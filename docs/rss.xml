<?xml version="1.0" encoding="utf-8"?>
 <rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
 <channel>
   <title>Datawarehouse f&#225;cil</title>
   <atom:link href="https://datawarehouse.es/rss.xml" rel="self" type="application/rss+xml" />
   <link>https://datawarehouse.es</link>
   <description></description>

 <item>
      <guid isPermaLink="true">https://datawarehouse.es/2015/el-futuro-es-brillante.html</guid>
      <link>https://datawarehouse.es/2015/el-futuro-es-brillante.html</link>
      <title>Consejo de dise&#241;o #180, El Futuro es brillante</title>
      <pubDate>Tue, 01 Dec 2015 22:52:19 GMT</pubDate>
      <atom:updated>2015-12-01T22:52:19Z</atom:updated>
      <description>
	  &lt;div style=&quot;width:700px&quot;&gt;&lt;img class=&quot;w100p&quot; src=&quot;https://datawarehouse.es/blog/images/&quot; /&gt;
	  &lt;p&gt;El &lt;em&gt;datawarehousing&lt;/em&gt; nunca ha sido tan valioso e interesante como es ahora. Tomar decisiones basadas en los datos es tan fundamental y obvio que la generaci&#243;n actual de usuarios de negocio y dise&#241;adores/implementadores de data warehouses no podr&#237;an imaginar un mundo sin acceso a los datos. Me resistir&#233; al impulso de contar historias sobre como era antes de 1980.&lt;/p&gt;
&lt;p&gt;Pero este es un momento de cambio en la pr&#225;ctica del datawarehousing. Es esencial que el &amp;quot;data warehousing&amp;quot; siempre recopile las necesidades del negocio y enumere todos los activos de datos de una organizaci&#243;n en el sentido m&#225;s amplio posible. Si el DWH se relega simplemente a informar sobre datos de  textos y m&#233;tricas obtenidos a partir de los registros transaccionales, entonces grandes oportunidades se perder&#225;n.&lt;/p&gt;
&lt;p&gt;El data warehousing ha definido una arquitectura para la &lt;em&gt;publicaci&#243;n de los datos correctos&lt;/em&gt; &#250;til para aquellos que toman las decisiones, y esa arquitectura recibe nombres: modelado dimensional, tablas de hechos, tablas dimensionales, claves subrogadas, dimensiones de variaci&#243;n lenta, dimensiones conformadas y muchas m&#225;s.&lt;/p&gt;
&lt;p&gt;Actualmente, est&#225;n teniendo lugar grandes cambios en mundo empresarial, con nuevos torrentes de datos procedentes de las redes sociales, texto libre, sensores y medidores, dispositivos de geoposicionamiento, sat&#233;lites, c&#225;maras y otros dispositivos de grabaci&#243;n. Los usuarios de negocio esperan tomar decisiones basadas en estas otras fuentes de datos.&lt;/p&gt;
&lt;p&gt;Marketing, el l&#237;der tradicional del DWH, compite ahora con los procesos de producci&#243;n y la investigaci&#243;n. Muchos de estos departamentos nuevos en el an&#225;lisis de datos construyen sus propios sistemas, normalmente de buena fe, pero ignorando el profundo legado y las habilidades arquitect&#243;nicas acumuladas del data warehousing. Es obligatorio para la comunidad DWH conocer a estos nuevos usuarios de negocio, no s&#243;lo para ofrecer nuestras &#250;tiles perspectivas, sino tambi&#233;n para aprender nosotros sobre estas nuevas &#225;reas de negocio.&lt;/p&gt;
&lt;p&gt;En este, mi &#250;ltimo consejo de dise&#241;o en el Grupo Kimball, describir&#233; como creo que est&#225;n cambiando los componentes m&#225;s importantes del data warehousing y como cambiar&#225;n en el futuro cercano. &#161;Es un momento emocionante y desafiante para ser un profesional del data warehouse!&lt;/p&gt;
&lt;h2&gt;El futuro del  ETL&lt;/h2&gt;
&lt;p&gt;Si el DWH va a abarcar todos los activos de datos de una organizaci&#243;n, entonces tendr&#225; que tratar con enormes torrentes de datos nuevos provenientes de datos estructurados de manera heterog&#233;nea. Diversos cambios importantes tendr&#225;n lugar en el entorno ETL: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Primero, los datos que se alimentan de fuentes originales deben soportar enormes anchos de banda, por lo menos gigabytes por segundo. Aprende sobre Sqoop cargando datos en Hadoop. Si estas palabras no significan nada para ti, &#161;tienes lecturas que hacer! Empieza con la Wikipedia.&lt;/li&gt;
&lt;li&gt;Segundo, muchos de los clientes anal&#237;ticos de estas nuevas corrientes de datos insisten en que no deben aplicar transformaciones  a los datos entrantes. En otras palabras, la zona inicial  del ETL debe ser capaz de almacenar archivos consistentes en bits no interpretados y sin suposiciones sobre c&#243;mo ser&#225; almacenado o analizado en la base de datos.&lt;/li&gt;
&lt;li&gt;Tercero, la arquitectura de almacenamiento debe ser abierta para que m&#250;ltiples herramientas de soporte de decisi&#243;n y clientes anal&#237;ticos puedan acceder a estos datos a trav&#233;s de una capa de metadatos universal.&lt;/li&gt;
&lt;li&gt;Y cuarto, la descripci&#243;n de metadatos de los archivos de datos de todo tipo debe ser m&#225;s extensible, adaptable y fuerte ya que nuevas fuentes de datos m&#225;s complejas estar&#225;n ahora disponibles. Hemos estado demasiado tiempo con archivos RDBMS simples de texto y n&#250;meros donde los metadatos contenidos en sistemas RDBMS tienen poca o ninguna sem&#225;ntica.  
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Los proveedores de RDBMS tienen el reto de diferenciar las capas de almacenamiento, de matadatos, y de consultas. Esto ya sucede en el entorno abierto Hadoop bajo el sistema de distribuci&#243;n de archivos (HDFS). Esto significa que el procesamiento ETL en algunas ocasiones puede ser retrasado hasta cierto punto en el tiempo despu&#233;s de que los datos hayan sido cargados en archivos accesibles. Las herramientas de consulta y an&#225;lisis, a trav&#233;s de los metadatos, deber&#225;n ser capaces de seleccionar el esquema objetivo en el momento de consulta (como una forma potente de virtualizaci&#243;n en el momento de la consulta, no en el momento de la carga). Tan inusual como suena un &lt;em&gt;&amp;quot;schema on read&amp;quot;&lt;/em&gt;, no es m&#225;s que otra forma de virtualizaci&#243;n de datos como las que hemos estado utilizando desde m&#225;s de una d&#233;cada.&lt;/p&gt;
&lt;p&gt;La desventaja de todas estas formas de virtualizaci&#243;n se encuentra en sustituir el c&#225;lculo en la fase de ETL, lo que tiene una penalizaci&#243;n significativa en el rendimiento. En alg&#250;n punto posterior a la fase exploratoria, el dise&#241;ador normalmente volver&#225; atr&#225;s y realizar&#225; un proceso normal ETL para preparar estructuras de archivos con m&#225;s prestaciones.&lt;/p&gt;
&lt;h2&gt;El futuro de la tecnolog&#237;a de base de datos&lt;/h2&gt;
&lt;p&gt;Las bases de datos relacionales son y ser&#225;n los fundamentos del data warehousing. Pero el RDBMS nunca se extender&#225; de una forma nativa a procesar todos los nuevos tipos de datos. Muchas de las herramientas anal&#237;ticas especializadas compiten ente ellas para analizar los datos, y gratamente coexisten con bases de datos RDBMS. Las bases de datos relacionales seleccionaran aquellos partes de los flujos de datos entrantes que puedan soportar.&lt;/p&gt;
&lt;p&gt;Otra cuesti&#243;n relacionada: Archivar nunca ser&#225; lo mismo. El almacenamiento en disco ha ganado la batalla como opci&#243;n para el almacenamiento a largo plazo por diversas razones, pero el factor m&#225;s significativo es el incre&#237;ble bajo coste por petabyte. Adem&#225;s el almacenamiento en disco siempre est&#225; en l&#237;nea, as&#237; los datos archivados permanecen activos y accesibles, esperando a nuevos modos de an&#225;lisis, y nuevas preguntas retrospectivas. A esto se llama archivado activo.&lt;/p&gt;
&lt;h2&gt;El futuro del modelado dimensional&lt;/h2&gt;
&lt;p&gt;Incluso en el desafiante nuevo mundo de extra&#241;os tipos de datos y procesamiento no relacional, el modelado dimensional es enormemente relevante. Incluso los tipos de datos m&#225;s extra&#241;os pueden ser tomados como un conjunto de observaciones recopilados en el mundo real. Estas observaciones siempre tienen contexto: fecha, hora, localizaci&#243;n, cliente/persona/paciente, acci&#243;n, etc. Estas, por supuesto, son nuestras dimensiones familiares. Cuando nos damos cuenta de ello, de repente toda la maquinaria dimensional que nos es familiar nos golpea. Podemos incluir cuidadas dimensiones de alta calidad desde nuestra fuente de datos EDW. Abrid vuestras mentes: Esta inclusi&#243;n no tiene que realizarse mediante la uni&#243;n de una base de datos relacional convencional, porque la correspondencia se puede hacer de otras formas.&lt;/p&gt;
&lt;p&gt;Las dimensiones, por supuesto, son el alma del data warehousing. Los hechos son meras observaciones que siempre existen en un contexto dimensional. Para ir m&#225;s lejos, podemos esperar que las dimensiones lleguen a ser m&#225;s importantes para poder apoyar un comportamiento m&#225;s sofisticado de las consultas de base y los an&#225;lisis predictivos. Ya ha habido propuestas para generalizar el esquema de la estrella, a un esquema supernova. En el esquema de una supernova, los atributos dimensionales llegan a ser objetos complejos y no un simple texto. Las dimensiones Supernova tambi&#233;n pasan a ser m&#225;s maleables y extensibles de una an&#225;lisis a otro. Compara el an&#225;lisis de la dimensi&#243;n del cliente tradicional con la dimensi&#243;n cliente supernova en la Figura 1. Date cuenta de que la mayor&#237;a de esto no son castillos en el aire.  Hoy puedes generalizar una simple dimensi&#243;n de un atributo en un ARRAY de STRUCTS. Hora de leer el manual de referencia SQL.&lt;/p&gt;
&lt;p&gt;&lt;mark&gt;IMAGEN&lt;/mark&gt; &lt;/p&gt;
&lt;p&gt;Figura 1: Dimensiones de cliente tradicional y supernova.&lt;/p&gt;
&lt;h2&gt;El futuro de las herramientas BI&lt;/h2&gt;
&lt;p&gt;El lugar de las herramientas BI aumentar&#225; para incluir m&#225;s tipos de an&#225;lisis no SQL. Por supuesto ya ha sucedido, especialmente en el entorno abierto Hadoop, y nosotros siempre nos hemos basado en herramientas potentes no SQL como SAS. De alg&#250;n modo, tocar&#225; definir de nuevo que es una herramienta BI. Comento este punto principalmente para empujar a los equipos de data warehousing a expandir su alcance y que no queden exclu&#237;dos de las nuevas fuentes de datos y nuevos tipos de an&#225;lisis.&lt;/p&gt;
&lt;h2&gt;El futuro de los profesionales del data warehousing&lt;/h2&gt;
&lt;p&gt;He resaltado muchas veces que un profesional con &#233;xito del data warehouse debe interesarse en tres cosas: el negocio, la tecnolog&#237;a y los usuarios de negocio. Esto siempre ser&#225; verdad en el futuro. Si quieres pasar el tiempo codificando y sin dirigirte a los usuarios de negocio, es genial pero no perteneces al equipo de data warehouse.&lt;/p&gt;
&lt;p&gt;Una vez dicho esto, los profesionales del DWH que quieran ir m&#225;s all&#225; necesitan tener habilidades en Unix y Java como m&#237;nimo, y estar familiarizado con algunos de los principales entornos anal&#237;ticos no SQL como Spark, MongoDB y HBase, as&#237; como herramientas de transferencia de datos como Sqoop.&lt;/p&gt;
&lt;p&gt;Creo que el reto m&#225;s emocionante es la expansi&#243;n de la descripci&#243;n del trabajo del profesional del DWH. De repente aparecen nuevos departamentos que intentan luchar con torrentes de datos y que probablemente est&#225;n reinventando la rueda del data warehouse. Encuentra cu&#225;les son estos departamentos y ed&#250;calos en la importancia de las dimensiones conformadas y las claves subrogadas. Ofr&#233;celes adjuntar tu dimensiones EDW de alta calidad a sus datos.&lt;/p&gt;
&lt;p&gt;Y como dice Margy: sal adelante y s&#233; dimensional&lt;/p&gt;
&lt;p&gt;Art&#237;culo original: &lt;a href=&quot;http://www.kimballgroup.com/2015/12/design-tip-180-the-future-is-bright/&quot;&gt;http://www.kimballgroup.com/2015/12/design-tip-180-the-future-is-bright/&lt;/a&gt;&lt;/p&gt;

	   
	  
	  &lt;/div&gt;</description>
</item>
 <item>
      <guid isPermaLink="true">https://datawarehouse.es/2015/modelado-dimensional-logico-o-fisico.html</guid>
      <link>https://datawarehouse.es/2015/modelado-dimensional-logico-o-fisico.html</link>
      <title>Consejo de dise&#241;o #176 Modelado dimensional; L&#243;gica o F&#237;sica</title>
      <pubDate>Tue, 28 Jul 2015 23:42:15 GMT</pubDate>
      <atom:updated>2015-07-28T23:42:15Z</atom:updated>
      <description>
	  &lt;div style=&quot;width:700px&quot;&gt;&lt;img class=&quot;w100p&quot; src=&quot;https://datawarehouse.es/blog/images/&quot; /&gt;
	  &lt;p&gt;Los modelos de datos dimensionales llevan aqu&#237; mucho tiempo. Ciertamente, casi podemos remontar sus or&#237;genes al proyecto original &lt;em&gt;Data Cube&lt;/em&gt; entre Dartmouth y General Mills a finales de 1960. La solicitud del modelado dimensional deriva de la evidente simplicidad de los modelos y de la forma natural en que la gente de negocios y la gente t&#233;cnica puedan entender lo que significan los modelos.&lt;/p&gt;
&lt;p&gt;Los modelos dimensionales tienen dos expresiones diferentes, l&#243;gica y f&#237;sica. La expresi&#243;n puramente l&#243;gica queda plasmada en el siguiente diagrama.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://datawarehouse.es/images/dt-176-figure.png&quot; alt=&quot;Imagen 1&quot; /&gt;&lt;/p&gt;
&lt;p&gt;La caja del centro siempre representa mediciones de sucesos (&amp;quot;l&#237;neas de pedido&amp;quot; en el ejemplo). Llamamos a estos hechos. Las cajas de alrededor representan las dimensiones naturales asociadas con las mediciones del suceso. Hay poco contenido t&#233;cnico de la base de datos en el diagrama del modelo l&#243;gico; pero mucho contenido de negocios. Una vez que la fuente de las mediciones de suceso ha sido identificada, el modelo l&#243;gico es el lugar donde empezar el dise&#241;o de forma seria.&lt;/p&gt;
&lt;p&gt;Una vez aceptado, el diagrama del modelo l&#243;gico se transformar&#225; con bastante rapidez a un dise&#241;o t&#233;cnico m&#225;s espec&#237;fico repleto de nombres de tablas, nombres de campos, y declaraciones de claves primarias y for&#225;neas. Esto es lo que piensan la mayor&#237;a de la gente IT de un modelo dimensional. Hmmm... esto parece muy f&#237;sico. Cuando este dise&#241;o f&#237;sico ha sido declarado, parece que el &#250;nico paso que queda es escribir el DDL expl&#237;cito creando las tablas objetivo, y despu&#233;s entrar en materia de  implementar las conexiones ETL para rellenar los datos de estas tablas f&#237;sicas.&lt;/p&gt;
&lt;p&gt;Espera. &#161;No tan r&#225;pido! Para ser honestos sobre este atractivo modelo f&#237;sico dimensional, tenemos que admitir que en el nivel real de almacenamiento f&#237;sico, nuestro modelo dimensional ser&#237;a implementado de manera muy diferente.  Los dos grandes &amp;quot;elefantes en la sala&amp;quot; son las bases de datos columnares y la virtualizaci&#243;n de datos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Las bases de datos columnares reorganizan radicalmente los datos en columnas comprimidas y ordenadas mientras crean la ilusi&#243;n modelo dimensional original.&lt;/li&gt;
&lt;li&gt;La virtualizaci&#243;n de datos transforma los datos f&#237;sicos actuales de casi cualquier forma original en el mismo momento de la consulta mientras crea una ilusi&#243;n de la apariencia exterior del modelo dimensional original. Las formas extremas de virtualizaci&#243;n de datos populares en el mundo Hadoop a veces son denominadas “vinculaci&#243;n diferida” (&lt;em&gt;deferred binding&lt;/em&gt;) o “esquema en lectura” (&lt;em&gt;schema on read&lt;/em&gt;). Pero en todos los casos el resultado final es el familiar modelo dimensional.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;En lugar de atascarnos en argumentos religiosos sobre modelos l&#243;gicos versus f&#237;sicos, debemos simplemente reconocer que un modelo dimensional es actualmente una interfaz de programaci&#243;n de aplicaciones (API) de data warehouse. El poder de esta API reside en la interfaz consistente y uniforme que ven todos los observadores, ambos usuarios y aplicaciones BI. Vemos que no importa donde est&#225;n almacenados los bits o como se entregan cuando se lanza una solicitud desde la API.&lt;/p&gt;
&lt;p&gt;El modelo dimensional API es muy espec&#237;fico. Debe exponer tablas de hechos, tablas dimensionales desnormalizadas y una columna para las claves subrogadas. La aplicaci&#243;n BI solicitante no puede y no debe ocuparse de c&#243;mo los grupos de resultados son implementados y entregados. Ahora vemos que la verdadera identidad del modelo dimensional es una API de data warehouse.&lt;/p&gt;
&lt;p&gt;Art&#237;culo original:  &lt;a href=&quot;http://www.kimballgroup.com/2015/07/design-tip-176-dimensional-models-logical-or-physical/&quot;&gt;http://www.kimballgroup.com/2015/07/design-tip-176-dimensional-models-logical-or-physical/&lt;/a&gt;&lt;/p&gt;

	   
	  
	  &lt;/div&gt;</description>
</item>
 <item>
      <guid isPermaLink="true">https://datawarehouse.es/2014/que-hay-en-un-nombre.html</guid>
      <link>https://datawarehouse.es/2014/que-hay-en-un-nombre.html</link>
      <title>Consejo de dise&#241;o #168. Que hay en un nombre</title>
      <pubDate>Sat, 21 Jun 2014 00:00:00 GMT</pubDate>
      <atom:updated>2014-06-21T00:00:00Z</atom:updated>
      <description>
	  &lt;div style=&quot;width:700px&quot;&gt;&lt;img class=&quot;w100p&quot; src=&quot;https://datawarehouse.es/blog/images/&quot; /&gt;
	  &lt;p&gt;Aunque parezca una cosa sin importancia, los nombres son importantes. Nombrar correctamente tablas y columnas es particularmente importante para los usuarios ad hoc del sistema DW/BI para que puedan encontrar lo que buscan. Los nombres de los objetos deben estar orientados a los usuarios de negocios, no al personal t&#233;cnico.&lt;/p&gt;
&lt;p&gt;Esfu&#233;rzate tanto como sea posible en no cambiar los nombres del sistema DW/BI en la capa sem&#225;ntica ni en los informes. M&#225;s complicado todav&#237;a: Se debe desincentivar que los usuarios cambien los nombres de los objetos una vez han seleccionado la informaci&#243;n. Por lo general, no podemos impedir que lo hagan, pero nombres atractivos y bien pensados reducir&#225;n la tentaci&#243;n de cambio.&lt;/p&gt;
&lt;p&gt;Aqu&#237; est&#225;n mis 10 mejores recomendaciones para nombrar objetos en el almac&#233;n de datos de tu sistema de inteligencia empresarial (BI).&lt;/p&gt;
&lt;h3&gt;1. Sigue la convenci&#243;n de nomenclatura.&lt;/h3&gt;
&lt;p&gt;Si no la tienes, crea (y documenta) una convenci&#243;n de nomenclatura que siga las reglas de este consejo de dise&#241;o. Si tu organizaci&#243;n ya tiene convenci&#243;n para la nomenclatura, te estar&#225;s enfrentando a un problema: la mayor&#237;a de las convenciones de nomenclatura existentes han sido desarrolladas por personal t&#233;cnico. Pero los nombres en el entorno DW/BI deben estar orientadas a los usuarios de negocios.  Se convierten en nombres de columnas y filas en los an&#225;lisis ad hoc y en los informes predefinidos. Volveremos a este tema m&#225;s adelante.&lt;/p&gt;
&lt;h3&gt;2. Cada objeto tiene un nombre.&lt;/h3&gt;
&lt;p&gt;No perpetuemos la confusi&#243;n en la definici&#243;n de datos ya existente en nuestras organizaciones. No es correcto decir que el equipo de ventas nombra a una columna Geograf&#237;a y el equipo de marketing nombra la misma columna como Regi&#243;n. Si no puedes llegar a un  acuerdo global en la organizaci&#243;n para nombrar objetos, debes solicitar la ayuda de tu responsable de negocios.&lt;/p&gt;
&lt;h3&gt;3. Los nombres de los objetos son descriptivos.&lt;/h3&gt;
&lt;p&gt;Los usuarios no necesitar estar 20 a&#241;os en tu organizaci&#243;n para poder descifrar el significado de un nombre. Esta regla evita muchas tonter&#237;as, como RBVLSPCD (&#161;tenemos m&#225;s de 8 car&#225;cteres para trabajar!). Tambi&#233;n proh&#237;be columnas como NOMBRE, que no es descriptivo fuera del contexto de la tabla que est&#225;s examinando.&lt;/p&gt;
&lt;h3&gt;4. No se recomiendan abreviaciones y acr&#243;nimos.&lt;/h3&gt;
&lt;p&gt;Las abreviaciones y acr&#243;nimos son end&#233;micas en el mundo corporativo, y en el mundo no corporativo es incluso peor. Mucha informaci&#243;n se puede codificar en un acr&#243;nimo pero para los novatos supone una enorme carga. El enfoque m&#225;s efectivo es mantener una lista de abreviaciones aprobadas, e intentar no ampliar sin una buena raz&#243;n. Deber&#237;as incluso documentar esa raz&#243;n en la lista.&lt;/p&gt;
&lt;p&gt;Algunos ejemplos incluir&#237;an:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://datawarehouse.es/images/abreviaturas.png&quot; alt=&quot;Imagen 1&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Para la mayor&#237;a de organizaciones, una lista razonable tiene docenas de abreviaciones aceptadas, no cientos.&lt;/p&gt;
&lt;h3&gt;5. Los nombres de los objetos son atractivos.&lt;/h3&gt;
&lt;p&gt;Recuerda que los nombres de los objetos se convierten en encabezados en informes y an&#225;lisis. Aunque el atractivo est&#225; en el ojo del que lee, para m&#237; son molestas todas las may&#250;sculas. Los nombres de objetos deben contener una pista visual sobre d&#243;nde terminan las palabras.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Espacios: [Columna Nombre]&lt;/li&gt;
&lt;li&gt;Camel case: Columna Nombre&lt;/li&gt;
&lt;li&gt;Destacar: Columna_Nombre o COLUMNA_NOMBRE&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Recomiendo utilizar espacios. Quedan mejor al incluirlos en los informes. Y me r&#237;o frente al argumento de que los desarrolladores tienen que mecanografiar corchetes cuando escriben el nombre de la columna. Estoy seguro de que cualquier desarrollador que actualmente teclee SQL puede descifrar donde est&#225;n colocados los par&#233;ntesis, y pueden desarrollar los m&#250;sculos de los dedos necesarios.&lt;/p&gt;
&lt;h3&gt;6. Los nombres de los objetos son &#250;nicos.&lt;/h3&gt;
&lt;p&gt;Esta regla es el corolario a la regla de que cada objeto tiene un nombre. Si dos objetos son diferentes, deben tener nombres diferentes. Esta regla proh&#237;be nombres de columna como [Ciudad]. Un nombre mejor es [ ciudad del cliente]. Esta regla es especialmente importante para el uso ad hoc del sistema DW/BI. Aunque el contexto de [Ciudad] es obvio durante el proceso anal&#237;tico, una vez que el contexto es guardado y compartido, se pierde. &#191;Buscamos la ciudad del cliente o la del almac&#233;n? &#191;la direcci&#243;n postal o la direcci&#243;n de env&#237;o? Aunque no podemos prevenir que los usuarios cambien el nombre de los objetos una vez exporten a Excel, no queremos forzarlos a hacerlo para as&#237; estar m&#225;s claro.&lt;/p&gt;
&lt;h3&gt;7. Nombres de objetos no demasiado largos.&lt;/h3&gt;
&lt;p&gt;Esta regla entra en conflicto con las reglas 3, 4 y 6. Si tenemos nombres de objetos &#250;nicos, sin abreviar, descriptivos es probable que algunos nombres de columnas sean muy largos. Consideremos [C&#243;digo de Salida de la Carta Obligatoria del Segundo Pagador] o [Proveedor de la Categor&#237;a de Referencia]. Estas descripciones de columnas son razonables en el negocio de los seguros, &#191;qu&#233; pasa cuando el usuario o el que realiza el informe utiliza esta columna para realizar un informe o an&#225;lisis? El nombre no quedar&#225; nada bien y el encabezamiento de la fila estar&#225; demasiado lleno. Se tendr&#237;a que reducir hasta un tama&#241;o de letra tan min&#250;sculo que nadie podr&#237;a leerlo. Entonces el usuario renombrar&#237;a la columna, violando nuestra regla clave de que cada objeto tiene un nombre. Yo intento limitar los nombres de las columnas a 30  caracteres, aunque a veces llego a 35. Para poder cumplir este objetivo, necesito registrar m&#225;s abreviaciones o acr&#243;nimos de los que me gustar&#237;a.&lt;/p&gt;
&lt;h3&gt;8. Considera anteponer a las columnas de nombre, una tabla abreviada del nombre.&lt;/h3&gt;
&lt;p&gt;Odio hacer esta recomendaci&#243;n, porque viola varias de mis reglas previas sobre abreviaciones y nombres cortos. Pero yo mismo me encuentro siguiendo esta pr&#225;ctica con frecuencia para garantizar la consistencia y unicidad.&lt;/p&gt;
&lt;h3&gt;9. Cambia los nombres en la capa de visualizaci&#243;n si es necesario.&lt;/h3&gt;
&lt;p&gt;Siempre hemos recomendado una &lt;em&gt;capa de vistas&lt;/em&gt; en el sistema DW/BI que se coloquen sobre las tablas f&#237;sicas.&lt;/p&gt;
&lt;p&gt;El objetivo principal de la capa de visualizaci&#243;n es establecer una capa que a&#237;sle las aplicaciones BI de la base de datos f&#237;sica, proporcionando un poco de flexibilidad para facilitar el camino de migrar a un sistema ya en producci&#243;n. Adicionalmente, la capa de visualizaci&#243;n puede proporcionar tambi&#233;n un lugar para poner los nombres orientados al negocio en la base de datos.&lt;/p&gt;
&lt;p&gt;Nuestra primera recomendaci&#243;n es siempre nombrar a las tablas y columnas f&#237;sica con nombres orientados al negocio. Si esto falla, utiliza la capa de visualizaci&#243;n. No nos gusta cambiar los nombres en las herramientas BI por diversas razones:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;La mayor&#237;a de organizaciones tienes diferentes herramientas BI; los nombres deben ser  coherentes para utilizarlos en la totalidad de las herramientas BI.&lt;/li&gt;
&lt;li&gt;Cuanta m&#225;s l&#243;gica de negocios apliques en la herramienta BI, mayor ser&#225; el reto de migrar a una herramienta diferente.&lt;/li&gt;
&lt;li&gt;Si los nombres est&#225;n solamente en la herramienta BI, existe una barrera comunicativa entre usuarios, el equipo de atenci&#243;n al cliente y la gente de mantenimiento de la base de datos.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;10. &#161;Se constante!&lt;/h3&gt;
&lt;p&gt;La necia coherencia es el duende de las mentes peque&#241;as. La coherencia en la nomenclatura es sumamente valiosa para sus usuarios.&lt;/p&gt;
&lt;p&gt;Art&#237;culo original: &lt;a href=&quot;http://www.kimballgroup.com/2014/07/design-tip-168-whats-name/&quot;&gt;http://www.kimballgroup.com/2014/07/design-tip-168-whats-name/&lt;/a&gt;&lt;/p&gt;

	   
	  
	  &lt;/div&gt;</description>
</item>
 <item>
      <guid isPermaLink="true">https://datawarehouse.es/2013/dar-sentido-capa-semnatica.html</guid>
      <link>https://datawarehouse.es/2013/dar-sentido-capa-semnatica.html</link>
      <title>Consejo de dise&#241;o #158, Dar sentido a la capa sem&#225;ntica</title>
      <pubDate>Mon, 05 Aug 2013 00:32:55 GMT</pubDate>
      <atom:updated>2013-08-05T00:32:55Z</atom:updated>
      <description>
	  &lt;div style=&quot;width:700px&quot;&gt;&lt;img class=&quot;w100p&quot; src=&quot;https://datawarehouse.es/blog/images/&quot; /&gt;
	  &lt;p&gt;Uno de los componentes clave de la arquitectura de un sistema Business Intelligence es la capa sem&#225;ntica. La capa sem&#225;ntica proporciona la traducci&#243;n de las estructuras subyacentes de la base de datos en t&#233;rminos y construcciones orientados  al usuario de negocio. Normalmente es una parte integrante de la herramienta de consulta e informe. Los sistemas OLAP o las bases de datos multi-dimensionales (cubos) tambi&#233;n incluyen una capa sem&#225;ntica.&lt;/p&gt;
&lt;p&gt;Algunas sistemas BI proporcionan capas sem&#225;nticas microsc&#243;picamente peque&#241;as, otras son ricas y robustas. La funcionalidad m&#237;nima para poder calificarse como una capa sem&#225;ntica incluye:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Una organizaci&#243;n que presenta los elementos de modo intuitivo para la gente de negocios. En la mayor&#237;a de las herramientas organizar&#225;s las tablas y columnas en estructuras de carpetas. El m&#233;todo Kimball te aconseja estructurar dimensionalmente tu almac&#233;n de datos, lo cu&#225;l te sit&#250;a por delante de aquellos que intentan lanzar BI directamente sobre estructuras de bases de datos transaccionales. Pero incluso si rehaces sobre un modelo dimensional limpio, una capa sem&#225;ntica proporcionar&#225; oportunidades para mejorar la navegabilidad y la capacidad de encontrar.&lt;/li&gt;
&lt;li&gt;Una oportunidad para renombrar los elementos de datos para que los usuarios de negocios encuentren sentido. Por supuesto, el m&#233;todo Kimball recomienda encarecidamente que las tablas y columnas del almac&#233;n de la base de datos sean nombrados como a los usuarios les gustar&#237;a verlos, pero esta funcionalidad se implementa a veces en la capa sem&#225;ntica.&lt;/li&gt;
&lt;li&gt;Una interfaz  para mantener las descripciones de los elementos de datos orientadas al negocio. Idealmente, tu almacenas y expones m&#250;ltiples tipos de metadatos: descripciones de negocios, valores de ejemplo, y la pol&#237;tica de cambios en las dimensiones de los atributos. En un mundo perfecto, la capa sem&#225;ntica de la BI expondr&#237;a al completo el n&#250;mero de l&#237;neas de cada elemento: que sistema de transacci&#243;n de datos era la fuente, que operario de ETL toc&#243;  este atributo, y cuando fue cargado en el almac&#233;n de datos. De modo realista, pocas capas sem&#225;nticas soportan m&#225;s de una &#250;nica descripci&#243;n para cada elemento de datos. En mi experiencia, la mayor&#237;a de equipos de DW/BI ni se molestan en enriquecer esa &#250;nica descripci&#243;n.&lt;/li&gt;
&lt;li&gt;Un mecanismo para definir reglas de c&#225;lculo y agregaci&#243;n. Por ejemplo, debes definir en el modelo sem&#225;ntico que balances de inventario son aditivos a trav&#233;s de la mayor&#237;a dimensiones, pero cuando se agregan a trav&#233;s del tiempo, necesitas tomar el periodo final del balance o dividir la suma de balances entre el n&#250;mero de periodos de tiempo.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&#191;La capa semantica es un complemento obligatorio de la arquitectura DW/BI? La respuesta es s&#237;, si planeas abrir tus puertas  a tu sistema DW/BI para un uso ad hoc. &lt;strong&gt;Cada hora que utilices construyendo una capa sem&#225;ntica rica se ver&#225; recompensada con las mejoras adoptadas y el &#233;xito en la comunidad de usuarios.&lt;/strong&gt; No ejecutes simplemente el asistente de tu herramienta BI que  genera una capa sem&#225;ntica equivalente a las tablas subyacentes (incluso si son dimensionales). Dedica tiempo para hacerla lo m&#225;s racional y precisa que puedas.&lt;/p&gt;
&lt;p&gt;La desventaja de invertir en una capa sem&#225;ntica es que tendr&#225;s que realizar la inversi&#243;n m&#250;ltiples veces. La mayor&#237;a de organizaciones se encuentran con que necesitan varias herramientas BI para encontrar las diversas necesidades de sus comunidades de usuarios. Cada herramienta tiene su propia capa sem&#225;ntica, que raramente puede ser copiada de una herramienta a otra (incluso en herramientas vendidas por el mismo vendedor). Uno de los muchos retos para los equipos de BI es mantener una apariencia y estructura organizacional similares en todas las herramientas BI. De nuevo, el m&#233;todo Kimball enfatiza que conseguir el modelo relacional correcto de datos dimensionales facilitar&#225; considerablemente la tarea de crear la capa sem&#225;ntica (haciendo m&#225;s fina la capa sem&#225;ntica de la herramienta BI).&lt;/p&gt;
&lt;p&gt;S&#243;lo hay un escenario donde me quedar&#237;a el argumento de que puedes funcionar sin una capa sem&#225;ntica. Si las puertas de tu sistema DW/BI est&#225;n cerradas a todos los usuarios ad hoc, y todo el acceso est&#225; intermediado por desarrolladores de informes corporativos, puedes hacerla funcionar sin una capa sem&#225;ntica BI. Esta es una recomendaci&#243;n no deseada en diversos frentes. Lo m&#225;s importante, &#191;c&#243;mo puedes cerrar las puertas a los usuarios ad hoc? Es una locura. Adicionalmente, los desarrolladores son personas tambi&#233;n e incluso pueden escribir SQL a mano y buscar definiciones en un diccionario de datos externo, Pero, &#191;por qu&#233; torturarlos?&lt;/p&gt;
&lt;p&gt;Si te quedas con el argumento de que necesitas una capa sem&#225;ntica, tu pr&#243;xima pregunta puede ser si necesitas un datawarehouse dimensional. Algunos observadores, especialmente algunos vendedores de herramientas BI, argumentan que puedes omitir el almac&#233;n de datos relacional y proporcionar la experiencia dimensional virtualmente. Esto suena atractivo, ya que nadie quiere realmente construir un sistema ETL, pero es una quimera. &lt;strong&gt;Ninguna herramienta de capa sem&#225;ntica proporciona la funcionalidad de transformaci&#243;n e integraci&#243;n de una herramienta ETL.&lt;/strong&gt; La mayor&#237;a de herramientas BI son estupendas en lo que hacen; no las corrompas por intentar hacer un ETL en la capa sem&#225;ntica. Y no olvides que el mantenimiento del ETL a&#241;ade valor a los datos limpiando, estandarizando, conformando y des-duplicando. Todos estos pasos una herramienta BI sencillamente no puede hacer.&lt;/p&gt;
&lt;p&gt;Lo dicho: He trabajado con clientes que han tenido &#233;xito enganchando una herramienta BI directamente al modelo de datos normalizado (transaccional o ODS). El escenario m&#225;s com&#250;n es un prototipo: Ense&#241;&#233;mosle a la gente  como ser&#237;a un universo de objetos de negocios o una interfaz Tableau para generar entusiasmo y apoyo financiero para un proyecto Business Intelligence.&lt;/p&gt;
&lt;p&gt;Otro escenario seria conocer los informes de requerimientos operacionales mediante la construcci&#243;n de una capa sem&#225;ntica sobre el sistema transaccional. Pero, en la mayor&#237;a de casos, esta capa sem&#225;ntica operacional es un componente relativamente menor en un entorno anal&#237;tico de una empresa que incluye un DWH real. Soy muy esc&#233;ptico con cualquier organizaci&#243;n que proclama que sus sistemas transaccionales est&#225;n lo suficientemente limpios, y sus necesidades anal&#237;ticas son bastante simples, que no necesitan  instanciar sus modelos dimensionales. No me opongo a la idea en la teor&#237;a, pero en la pr&#225;ctica todav&#237;a no lo veo funcionando.&lt;/p&gt;
&lt;p&gt;No creo que haya visto alguna vez que una organizaci&#243;n sobre-invirtiese en una capa sem&#225;ntica, pero he visto muchos data warehouses fallar debido a la falta de inversi&#243;n. Adquiere una herramienta BI decente (hay docenas), e invierte tiempo desarrollando la capa sem&#225;ntica. De lo contrario estar&#225;s subestimando tu sustancial inversi&#243;n en dise&#241;o y desarrollo de un data warehouse t&#233;cnicamente solido.&lt;/p&gt;
&lt;p&gt;Art&#237;culo original:  &lt;a href=&quot;http://www.kimballgroup.com/2013/08/design-tip-158-making-sense-of-the-semantic-layer/&quot;&gt;http://www.kimballgroup.com/2013/08/design-tip-158-making-sense-of-the-semantic-layer/&lt;/a&gt;&lt;/p&gt;

	   
	  
	  &lt;/div&gt;</description>
</item>
 <item>
      <guid isPermaLink="true">https://datawarehouse.es/2011/135-dimensiones-conformadas-fundamento-datawarehouse-agil.html</guid>
      <link>https://datawarehouse.es/2011/135-dimensiones-conformadas-fundamento-datawarehouse-agil.html</link>
      <title>Consejo de dise&#241;o #135. Las dimensiones conformadas como fundamento de un data warehouse &#225;gil</title>
      <pubDate>Wed, 01 Jun 2011 00:00:00 GMT</pubDate>
      <atom:updated>2011-06-01T00:00:00Z</atom:updated>
      <description>
	  &lt;div style=&quot;width:700px&quot;&gt;&lt;img class=&quot;w100p&quot; src=&quot;https://datawarehouse.es/blog/images/&quot; /&gt;
	  &lt;h2&gt;Consejo de dise&#241;o #135.&lt;/h2&gt;
&lt;p&gt;Algunos clientes y estudiantes lamentan que cuando quieren entregar y compartir dimensiones maestras definidas consistentemente en el entorno DWH/BI, simplemente, &amp;quot;no se puede&amp;quot;. Explican que lo har&#237;an si pudiesen, pero con una alta direcci&#243;n centrada en utilizar t&#233;cnicas de desarrollo &#225;gil para ofrecer soluciones DW/BI, es &amp;quot;imposible&amp;quot; tener tiempo para llegar a un acuerdo en toda la organizaci&#243;n sobre dimensiones conformadas. Quiero llevar a cabo este argumento al rev&#233;s afirmando que &lt;strong&gt;las dimensiones conformadas permiten el desarrollo &#225;gil de DW/BI  y agiliza la toma de decisiones&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Se&#225;is o no un especialista Kimball, muchos de vosotros est&#225;is familiarizados con las dimensiones conformadas. Una dimensi&#243;n conformada es un dato maestro descriptivo que est&#225; referenciado en m&#250;ltiples modelos dimensionales. Las dimensiones conformadas son fundamentales dentro del enfoque Kimball. Las dimensiones conformadas permiten a  los usuarios del DW/BI cortar y fragmentar constantemente las m&#233;tricas de rendimiento de los procesos de fuentes de datos procedentes de m&#250;ltiples empresas. Las dimensiones conformadas permiten que datos de diferentes fuentes sean integrados bas&#225;ndose en atributos de dimensiones comunes y unificados. Finalmente, las dimensiones conformadas permiten construir y mantener una tabla de datos una sola vez en lugar de recrear versiones ligeramente diferentes durante cada ciclo de desarrollo.&lt;/p&gt;
&lt;p&gt;Reutilizando dimensiones conformadas entre proyectos es  donde se obtiene un impulso para obtener m&#225;s agilidad en el desarrollo  DW/BI. A medida que desarrollas tu portfolio de dimensiones maestras conformadas, la manivela de desarrollo del proyecto empieza a girar m&#225;s r&#225;pido.&lt;/p&gt;
&lt;p&gt;El &lt;em&gt;time-to-market&lt;/em&gt; de una nueva fuente de datos empresarial se reduce a medida que los desarrolladores reutilizan dimensiones conformadas existentes. Finalmente, los nuevos desarrollos ETL se centrar&#225;n casi exclusivamente en entregar m&#225;s tablas de hechos a medida que las tablas de dimensiones asociadas preparadas en su estanter&#237;a listas para ser utilizadas.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Definir una dimensi&#243;n conformada requiere un consenso organizacional y compromiso en la organizaci&#243;n.&lt;/strong&gt; No es necesario que todos est&#233;n de acuerdo con cada atributo en cada tabla dimensional. Como m&#237;nimo, deber&#237;as identificar un subconjunto de atributos que tenga significado en la empresa. Estas caracter&#237;sticas descriptivas comunes son el punto de partida de los atributos conformados.&lt;/p&gt;
&lt;p&gt;A lo largo del tiempo, puedes expandir este sencillo punto de partida de manera iterativa. Ninguno de los atributos dimensionales especiales procedentes de un solo proceso empresarial no deben ser descartados durante el proceso de conformaci&#243;n (asumimos muy pocos compromisos definitivos). Y finalmente, si tu organizaci&#243;n ya ha implementado la capacidad de &lt;em&gt;master data managment&lt;/em&gt; (MDM) para apoyar el sistema de fuente transaccional, el trabajo de crear dimensiones conformadas para el almac&#233;n de datos de la empresa, ser&#225; m&#225;s sencillo.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Si fallas en concentrarte en las dimensiones conformadas porque est&#225;s bajo presi&#243;n de entregar alguna cosa, los distintos departamentos anal&#237;ticos de silos de datos probablemente tendr&#225;n categor&#237;as y etiquetas inconsistentes&lt;/strong&gt;. O peor: Los conjuntos de datos ofrecer&#225;n la apariencia de poder ser comparados y integrados debido a la similitud de sus etiquetas, pero las reglas empresariales subyacentes ser&#225;n ligeramente diferentes. Los usuarios de negocio malgastar&#225;n cantidades exageradas de tiempo intentando componer y resolver estas inconsistencias en los datos que influir&#225;n negativamente en su agilidad para la toma de decisiones.&lt;/p&gt;
&lt;p&gt;Los altos directivos de IT que demandan desarrollo de sistemas &#225;giles, si est&#225;n interesados en conseguir eficiencia en el desarrollo a largo plazo y quieren una toma de decisiones efectiva en la empresa a largo plazo, deber&#225;n ejercer incluso una mayor presi&#243;n a la organizaci&#243;n para definir dimensiones conformadas consistentes .&lt;/p&gt;
&lt;p&gt;Art&#237;culo original: &lt;a href=&quot;http://www.kimballgroup.com/2011/06/design-tip-135-conformed-dimensions-as-the-foundation-for-agile-data-warehousing/&quot;&gt;http://www.kimballgroup.com/2011/06/design-tip-135-conformed-dimensions-as-the-foundation-for-agile-data-warehousing/&lt;/a&gt;&lt;/p&gt;

	   
	  
	  &lt;/div&gt;</description>
</item>
 <item>
      <guid isPermaLink="true">https://datawarehouse.es/2011/recomendaciones-testing-datawarehouse.html</guid>
      <link>https://datawarehouse.es/2011/recomendaciones-testing-datawarehouse.html</link>
      <title>Consejo de die&#241;o #134. Recomendaciones para las pruebas del Data Warehouse</title>
      <pubDate>Wed, 04 May 2011 00:03:27 GMT</pubDate>
      <atom:updated>2011-05-04T00:03:27Z</atom:updated>
      <description>
	  &lt;div style=&quot;width:700px&quot;&gt;&lt;img class=&quot;w100p&quot; src=&quot;https://datawarehouse.es/blog/images/&quot; /&gt;
	  &lt;p&gt;La validaci&#243;n de un entorno datawarehouse/BI es un gran reto. La metodolog&#237;a de validaci&#243;n est&#225;ndar valida s&#243;lo una peque&#241;a cosa a la vez. Sin embargo, la naturaleza de un sistema DW/BI versa sobre integraciones complejas, sin mencionar el elevado volumen de datos. Aqu&#237; est&#225;n mis 5 recomendaciones principales para construir y ejecutar un test en el entorno de tu proyecto DW/BI.&lt;/p&gt;
&lt;h2&gt;1. Crea un peque&#241;o test est&#225;tico de la base de datos, derivado de los datos reales.&lt;/h2&gt;
&lt;p&gt;Necesitas que sea peque&#241;o para que el test se realice r&#225;pidamente. Necesitas que sea est&#225;tico para conocer de antemano los resultados esperados. Y necesitas que derive de datos reales porque no hay nada como los datos reales para ofrecer una combinaci&#243;n realista de escenarios buenos y malos. Necesitar&#225;s a&#241;adir filas en el test de la base de datos para probar que cada una de las instrucciones de tu c&#243;digo ETL cubre un escenario no incluido en el test de datos original.&lt;/p&gt;
&lt;h2&gt;2. Comprueba pronto y con regularidad.&lt;/h2&gt;
&lt;p&gt;Empieza comprobando tan pronto como escribas una l&#237;nea de c&#243;digo (o conectas dos cajas en el UI de tu herramienta ETL). Los desarrolladores hacen esto todo el tiempo, por supuesto. Desarrollar implica poner en marcha tests unitarios para asegurar que su c&#243;digo funciona como se espera. Muchos desarrolladores no son tan buenos siguiendo la evoluci&#243;n de esas pruebas y realiz&#225;ndolas frecuentemente. Diariamente. Cada vez que se realiza un commit en tu c&#243;digo. Si realizas el test cada d&#237;a, y priorizas en mejorar cada test que fall&#243; ayer, ser&#225; m&#225;s f&#225;cil determinar aquello que no funcion&#243;.&lt;/p&gt;
&lt;p&gt;La prueba unitaria asegura que el c&#243;digo desarrollado funciona tal y como se ha dise&#241;ado. La prueba del sistema asegura que el sistema en completo funciona, de acuerdo con las especificaciones. La prueba del sistema tambi&#233;n se deber&#237;a realizar pronto.&lt;/p&gt;
&lt;p&gt;Hay una &amp;quot;fase de test&amp;quot; oficial antes de la puesta en funcionamiento del DWH. Esta fase de tests es para llevar a cabo las pruebas y reconocer problemas, no para identificar como deber&#237;an ser los tests y como llevarlos a cabo. &lt;strong&gt;Se debe  empezar a probar el sistema al inicio del proceso de desarrollo&lt;/strong&gt;, de esta manera todos los detalles se resuelven mucho antes de empezar con la &amp;quot;fase de test&amp;quot; oficial, que supone mayor presi&#243;n para el funcionamiento correcto del sistema.&lt;/p&gt;
&lt;h2&gt;3. Utilizar herramientas de prueba y automatizar el entorno de prueba.&lt;/h2&gt;
&lt;p&gt;La recomendaci&#243;n de hacer el test pronto y regularmente es pr&#225;ctica solamente si automatizas el proceso. Ning&#250;n desarrollador va a utilizar hasta la &#250;ltima de su d&#237;a de trabajo haciendo de ni&#241;era de la prueba unitaria. Y pocos equipos pueden permitirse un controlador a tiempo completo para hacer ese trabajo en lugar del desarrollador. Para automatizar la prueba, necesitas herramientas. Muchas organizaciones ya disponen “in situ” de herramientas para comprobar la calidad de las pruebas. Si tu no las tienes, o est&#225;s convencido de que las herramientas de las que dispones no responden a las necesidades de control del sistema DW/BI, intenta buscar en google “herramientas de software para asegurar la calidad” para disponer de una inmensa lista de productos y metodolog&#237;as disponibles a una extensa gama de precios.&lt;/p&gt;
&lt;p&gt;Todos los software comerciales de herramientas de prueba te permitir&#225;n formular tests, ejecutar tests, registrar los resultados de los tests realizados y informar de esos resultados. Para la prueba de la unidad y prueba de la calidad de los datos, define los tests para llevar a cabo una consulta en la fuente y el objetivo del almac&#233;n de datos. &lt;strong&gt;Tienes que buscar el recuento de filas y cantidades para hacerlas coincidir.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Una herramienta de testing utilizada para probar el DW/BI debe ser capaz de ejecutar un escenario que establezca el entorno de prueba antes de que las pruebas se lleven a cabo. Las tareas que necesitar&#225; ejecutar incluyen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Restaurar un entorno de m&#225;quina virtual con un test de datos limpio.&lt;/li&gt;
&lt;li&gt;Modificar el test est&#225;tico de datos con filas especiales para probar condiciones inusuales.&lt;/li&gt;
&lt;li&gt;Ejecutar tu programa ETL&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Despu&#233;s de ejecutar y registrar los tests, termina con un &lt;em&gt;script&lt;/em&gt; de limpieza, que deber&#237;a ser tan simple como eliminar el entorno VM.&lt;/p&gt;
&lt;p&gt;La metodolog&#237;a de prueba est&#225;ndar cambia una cosa, ejecuta un test y registra los resultados. En el mundo del DW/BI, debes agrupar juntos muchos tests en un grupo de tests. Incluso con una base de datos peque&#241;a, no tienes que ejecutar tu c&#243;digo ETL para cada una de los centenares de unidades que deber&#237;an estar funcionando.&lt;/p&gt;
&lt;h2&gt;4. Haz una lista de los usuarios de negocios para definir los tests del sistema.&lt;/h2&gt;
&lt;p&gt;Necesitamos la experiencia de los usuarios para definir buenos tests para el sistema. &#191;C&#243;mo sabemos que los datos son correctos? &#191;C&#243;mo sabemos que el rendimiento de las consultas cumple sus expectativas? Hacer una lista de los usuarios de negocios durante el proceso de especifiaci&#243;n del test asegurar&#225; una mejor prueba que si simplemente el equipo DW/BI construye tests basados en lo que creen que es interesante. Contar con los usuarios de negocios clave en el proceso de aseguramiento de la calidad tambi&#233;n proporciona un impulso enorme en la credibilidad.&lt;/p&gt;
&lt;h2&gt;5. El test del entorno debe ser tan similar como sea posible al entorno de producci&#243;n.&lt;/h2&gt;
&lt;p&gt;Es de vital importancia que el entorno de test sea similar al de producci&#243;n. Ser&#237;a ideal que fuese el mismo hardware, software y configuraci&#243;n. En el mundo real, relativamente pocas organizaciones tienen presupuesto para tener dos servidores DW grandes. Pero cualquier organizaci&#243;n puede, y debe, hacer coincidir los siguientes elementos:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Configuraci&#243;n de la unidad (nombres relativos de las unidades). El disco es barato y debes ser capaz de duplicar tu disco para su test. Pero si no puedes, al menos haz que los escritos de la unidad y el archivo de la base de datos tengan la misma disposici&#243;n. Mucha gente se queja de que esto significa mucho trabajo para cambiar el entorno . &#161;Lo es! Y es mucho mejor hacerlo ahora que en la fase final del test de tu proyecto.&lt;/li&gt;
&lt;li&gt;Las versiones de software del sistema operativo de la base de datos con la base de datos de los escritorios de los usuarios, y todo aquello que los relacione.&lt;/li&gt;
&lt;li&gt;Dise&#241;o del servidor. Si el software de reporting est&#225; en su propio servidor de producci&#243;n, pru&#233;balo de esa manera.&lt;/li&gt;
&lt;li&gt;Roles de seguridad y privilegios para las cuentas de mantenimiento. Tu despliegue est&#225; virtualmente relegado al fracaso si no compruebas los roles de seguridad primero. No s&#233; porque, pero siempre parece que va a ir mal.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Si sigues estas sugerencias, especialmente la sugerencia de probar continuamente, probablemente tengas una fase de test agradable y sin crisis y cumplir&#225;s el hito de pase a producci&#243;n en  la fecha programada.&lt;/strong&gt;  Si no, est&#225;s corriendo un serio riesgo de retrasar interminablemente un fabuloso proyecto en el infierno QA, con los usuarios de negocios y la direcci&#243;n llamando a tu puerta.&lt;/p&gt;
&lt;p&gt;Art&#237;culo original: &lt;a href=&quot;http://www.kimballgroup.com/2011/05/design-tip-134-data-warehouse-testing-recommendations/&quot;&gt;http://www.kimballgroup.com/2011/05/design-tip-134-data-warehouse-testing-recommendations/&lt;/a&gt;&lt;/p&gt;

	   
	  
	  &lt;/div&gt;</description>
</item>
 <item>
      <guid isPermaLink="true">https://datawarehouse.es/2009/seis-claves-para-elegir-arquitectura-etl.html</guid>
      <link>https://datawarehouse.es/2009/seis-claves-para-elegir-arquitectura-etl.html</link>
      <title>Seis claves para elegir la arquitectura ETL</title>
      <pubDate>Fri, 09 Oct 2009 22:08:14 GMT</pubDate>
      <atom:updated>2009-10-09T22:08:14Z</atom:updated>
      <description>
	  &lt;div style=&quot;width:700px&quot;&gt;&lt;img class=&quot;w100p&quot; src=&quot;https://datawarehouse.es/blog/images/&quot; /&gt;
	  &lt;p&gt;Este art&#237;culo describe seis decisiones clave que deben incluirse durante la elaboraci&#243;n de la arquitectura ETL para un DWH dimensional. Estas decisiones tienen un impacto importante en el coste inicial y coste corriente y en la complejidad de la soluci&#243;n ETL y, finalmente, en el &#233;xito de toda la soluci&#243;n BI/DW en global.&lt;/p&gt;
&lt;h2&gt;1. &#191;Debemos utilizar una herramienta ETL?&lt;/h2&gt;
&lt;p&gt;Una de las primeras y m&#225;s fundamentales decisiones que debes tomar es si codificar tu proceso ETL a mano desde cero, o si debes utilizar un software espec&#237;fico de un proveedor. Dejando de lado  las cuestiones t&#233;cnicas y los costes de licencia, no debes adoptar un m&#233;todo que a tus empleados y directores no les sea familiar sin considerar seriamente las implicaciones a largo plazo de estas decisiones. Esta decisi&#243;n tendr&#225; un mayor impacto en el contexto del ETL, guiando decisiones respecto al personal, dise&#241;ando enfoques, estrategias de metadatos, y implementando cronolog&#237;as a largo plazo.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;En el contexto actual, la mayor&#237;a de organizaciones deben usar un software suministrado por un proveedor.&lt;/strong&gt; Sin embargo, esta decisi&#243;n debe tomarse en base a los recursos disponibles para construir y dirigir el sistema. Las herramientas ETL construyen entornos que usan iconos, flechas y propiedades en lugar de escribir c&#243;digo para construir la soluci&#243;n ETL. Ten cuidado: Si tu equipo de desarrollo del ETL est&#225; integrado por cierto n&#250;mero de programadores de la vieja escuela, es posible que no se adapten bien a una herramienta ETL. S&#243;lo por esta raz&#243;n, algunas organizaciones piensan que un ETL personalizado es una soluci&#243;n razonable.&lt;/p&gt;
&lt;p&gt;Si decides utilizar una herramienta ETL, no esperes una gran amortizaci&#243;n en tu primera iteraci&#243;n. Las ventajas aparecer&#225;n a medida que realices iteraciones adicionales y empieces a aprovechar las ventajas de utilizar la herramienta en las siguientes implementaciones. Tambi&#233;n experimentar&#225;s los beneficios en la capacidad de mantenimiento, documentaci&#243;n m&#225;s completa y soporte mejorado para los metadatos.&lt;/p&gt;
&lt;h2&gt;2. &#191;D&#243;nde y c&#243;mo debe tener lugar la integraci&#243;n de datos?&lt;/h2&gt;
&lt;p&gt;La integraci&#243;n de datos es un tema important&#237;simo para IT porque, b&#225;sicamente, se trata de hacer que todos los sistemas trabajen juntos eficientemente. La &amp;quot;visi&#243;n de 360 de la empresa&amp;quot; es un objetivo com&#250;nmente discutido que realmente implica la integraci&#243;n de datos. En muchos casos, la integraci&#243;n de datos debe realizarse en los sistemas de transacciones primarios de la organizaci&#243;n antes de que los datos lleguen al data warehouse. Sin embargo, antes que enfrentarse a la integraci&#243;n en el entorno operacional, estos requisitos son normalmente encargados al DWH y al sistema ETL.&lt;/p&gt;
&lt;p&gt;La mayor&#237;a de nosotros entendemos el concepto principal de que la integraci&#243;n permite que bases de datos dispares funcionen juntas de una manera &#250;til. Todos sabemos que lo necesitamos, simplemente no tenemos una idea clara de c&#243;mo dividirlo en partes manejables.&lt;/p&gt;
&lt;p&gt;&#191;Integraci&#243;n significa que todas las partes de grandes organizaciones est&#233;n de acuerdo con cada dato o s&#243;lo con alguno de ellos? Este es el punto crucial de la decisi&#243;n que se debe tomar. &#191;En qu&#233; datos la direcci&#243;n empresarial est&#225; de acuerdo/insiste que suceda? &#191;Est&#225;n dispuestos a establecer definiciones comunes entre la organizaci&#243;n y atenerse a esas definiciones?&lt;/p&gt;
&lt;p&gt;Fundamentalmente, integraci&#243;n significa llegar a un acuerdo en el sentido de los datos desde la perspectiva de dos o m&#225;s bases de datos. Con la integraci&#243;n, los resultados de dos bases de datos pueden ser combinados en un solo an&#225;lisis del DWH. Sin un acuerdo, las bases de datos permanecer&#225;n aisladas y no se podr&#225;n enlazar en una aplicaci&#243;n. En el contexto de nuestro entorno ETL, la integraci&#243;n de datos toma la forma de las dimensiones acordadas y de los hechos establecidos en el almac&#233;n de datos. Las dimensiones acordadas hacen referencia a establecer atributos dimensionales comunes entre tablas de hechos separadas de forma que informes puedan ser generados utilizando estos atributos. Los hechos establecidos hacen referencia a acuerdos en m&#233;tricas comunes de negocios como los indicadores de actividad (KPIs) entre bases de datos separadas, para que estos n&#250;meros puedas ser comparados matem&#225;ticamente para calcular diferencias y ratios.&lt;/p&gt;
&lt;h2&gt;3. &#191;Qu&#233; mecanismo de recopilaci&#243;n de cambios de datos debemos escoger?&lt;/h2&gt;
&lt;p&gt;Durante la carga inicial del hist&#243;rico de datos del almac&#233;n de datos, recopilar cambios contenidos en las fuentes de datos no es importante ya que est&#225;s cargando datos en un punto futuro. Sin embargo, la mayor&#237;a de tablas del almac&#233;n de datos son tan extensas que no pueden ser actualizadas durante cada ciclo ETL. Debes tener la capacidad de transferir s&#243;lo los cambios relevantes para la fuente de datos  desde la &#250;ltima actualizaci&#243;n. Aislar la &#250;ltima fuente de datos se denomina recopilaci&#243;n de cambio de datos (&lt;em&gt;change data capture&lt;/em&gt;, CDC). &lt;strong&gt;La idea detr&#225;s de recopilar el cambio de datos es bastante simple: transferir solamente los datos que han sido cambiados desde la &#250;ltima actualizaci&#243;n.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Pero construir un buen sistema de recopilaci&#243;n de cambio de datos no es tan f&#225;cil como suena. Asumamos  que el mecanismo seleccionado debe ser totalmente fiable y a prueba de fallos. Todos los datos cambiados deben ser identificados. Encontrar la estrategia m&#225;s completa puede ser evasivo, muchas veces la actualizaci&#243;n de los sistemas de tablas de la fuente puede ocurrir fuera de la misma aplicaci&#243;n. Un error aqu&#237;, provocar&#225; resultados que no podr&#225;n ser explicados f&#225;cilmente; frecuentemente esto deriva en la recuperaci&#243;n de datos para identificar el culpable.&lt;/p&gt;
&lt;p&gt;Los problemas pueden significar elevados costes en t&#233;rminos de rehacer el trabajo-sin mencionar la situaci&#243;n embarazosa. En resumen, &lt;strong&gt;recopilar los cambios de datos est&#225; lejos de ser una tarea trivial, y debes entender muy bien los sistemas de fuente de datos.&lt;/strong&gt; Este conocimiento ayudar&#225; al equipo ETL a evaluar las fuentes de datos, identificar problemas en  la recopilaci&#243;n de los cambios de datos y determinar la estrategia m&#225;s apropiada.&lt;/p&gt;
&lt;h2&gt;4. &#191;Cuando debemos almacenar los datos?&lt;/h2&gt;
&lt;p&gt;En el entorno actual de almacenamiento de datos, es bastante posible para las herramientas ETL establecer una conexi&#243;n directa con la fuente de la base de datos, extraer los datos, aplicar cualquier transformaci&#243;n requerida en la memoria y, finalmente, escribirla- s&#243;lo una vez- en la tabla objetivo del DWH. Desde el punto de vista de rendimiento, esta es una gran capacidad ya que el coste de escritura es elevado. Minimizar el n&#250;mero de escrituras en un buen objetivo de dise&#241;o.&lt;/p&gt;
&lt;p&gt;Sin embargo, a pesar de las ventajas de rendimiento, este puede no ser el mejor planteamiento. Hay diversas razones por las que una organizaci&#243;n puede decidir para almacenar los datos f&#237;sicamente  (por ejemplo, escribirlos en un disco) durante el proceso ETL:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;El m&#233;todo CDC m&#225;s apropiado requiere comparar la copia actual de la tabla fuente con la copia precedente de la misma tabla.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;La organizaci&#243;n ha elegido almacenar los datos inmediatamente despu&#233;s de la extracci&#243;n con el prop&#243;sito de archivar (posiblemente para cumplir los requerimientos de auditoria y control).&lt;/li&gt;
&lt;li&gt;A veces se requiere un punto de recuperaci&#243;n/reinicio cuando el ETL falla a mitad del trabajo.&lt;/li&gt;
&lt;li&gt;Los procesos ETL que se desarrollan durante largos per&#237;odos pueden abrir una conexi&#243;n con el sistema fuente que crea problemas con bloqueos de la base de datos y sobrecarga el sistema de transacciones.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;5. &#191;D&#243;nde debemos corregir los datos?&lt;/h2&gt;
&lt;p&gt;Los usuarios de negocios son conscientes de que la calidad de los datos es un problema serio y caro. Por este motivo, a la mayor&#237;a de organizaciones les gusta apoyar iniciativas para mejorar la calidad de los datos. Pero la mayor&#237;a de los usuarios probablemente no tienen ni idea de d&#243;nde se originan los problemas de calidad de los datos o que se debe hacer para mejorar la calidad de los datos. Deben pensar que la calidad de los datos es un simple problema de ejecuci&#243;n del equipo ETL. En este entorno, el equipo ETL necesita ser &#225;gil y proactivo:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;La calidad de los datos no puede ser mejorada solamente por el ETL.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;La clave est&#225; en que el equipo de ETL colabore con la empresa y los equipos de soporte del sistema fuente del IT.&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;La decisi&#243;n clave es d&#243;nde corregir los datos. Claramente, la mejor soluci&#243;n es recopilar correctamente los datos en el momento que se generan. Por supuesto, este no es siempre el caso, pero &lt;strong&gt;en la mayor&#237;a de casos los datos deben ser corregidos en sistema fuente.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Sin embargo, desafortunadamente, es inevitable que datos de poca calidad lleguen al sistema ETL. En este caso, hay tres opciones:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Detener el proceso de carga.&lt;/li&gt;
&lt;li&gt;Enviar los registros da&#241;ados a un archivo temporal para su posterior procesamiento.&lt;/li&gt;
&lt;li&gt;&#218;nicamente etiquetar los datos y continuar&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;La tercera opci&#243;n es por mucho la mejor (siempre que sea posible). Detener el proceso es obviamente doloroso porque requiere intervenci&#243;n manual para diagnosticar el problema, reiniciar o reanudar el trabajo, o abortar completamente. Enviar registros a un archivo temporal siempre es una soluci&#243;n pobre porque no est&#225; claro cu&#225;ndo estos registros ser&#225;n revisados e introducidos en el DWH. Hasta que los registros son restaurados al flujo de datos, la integridad global de la base de datos es cuestionable ya que estos registros est&#225;n perdidos. Recomiendo no utilizar el archivo temporal para infracciones menores de datos.&lt;/p&gt;
&lt;p&gt;La tercera opci&#243;n de etiquetar los datos con la condici&#243;n de error normalmente funciona bien. La tabla de hechos err&#243;nea puede ser etiquetada con una dimensi&#243;n de control que describe la condici&#243;n de calidad global de la fila del hecho problem&#225;tico. Los datos mal dimensionados tambi&#233;n pueden ser etiquetados con un valores &#250;nicos de error en el mismo campo. En este punto, las soluciones de &lt;em&gt;data quality&lt;/em&gt; pueden ayudar aidentificar el hecho problem&#225;tico y las filas de dimensi&#243;n.&lt;/p&gt;
&lt;h2&gt;6. &#191;Con que rapidez debe estar disponible la informaci&#243;n de origen en el sistema DW/BI?&lt;/h2&gt;
&lt;p&gt;La latencia de  los datos  describe con qu&#233; frecuencia los datos fuente deben ser proporcionados a los usuarios de negocio v&#237;a el sistema DW/BI. La latencia de los datos obviamente tiene un gran efecto en el coste y la complejidad de tu entorno ETL. Algoritmos de procesamiento inteligentes, paralelizaci&#243;n,  y hardware potente pueden acelerar el flujo de carga (tradicionalmente orientado por lotes). Pero en alg&#250;n momento, si el requerimiento de la latencia de datos es suficientemente urgente, el proceso ETL debe pasar de estar orientado a lotes a estar orientado a flujos. Este cambio no es gradual ni evolutivo. Es un cambio de paradigma que puede implicar la re-implementaci&#243;n completa del sistema ETL.&lt;/p&gt;
&lt;p&gt;Habitualmente, el proceso ETL requiere una latencia de datos acorde al ritmo natural del negocio. &lt;strong&gt;En la mayor&#237;a de organizaciones esto se traduce en actualizaciones diarias para la mayor&#237;a de procesos  ETL y actualizaciones semanales o mensuales para otros procesos ETL.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Sin embargo, en algunas circunstancias, el ritmo del negocio requiere actualizaciones m&#225;s frecuentes o incluso actualizaciones en tiempo real. La clave es reconocer que s&#243;lo un pu&#241;ado de procesos empresariales dentro de una organizaci&#243;n son apropiados para realizar actualizaciones en tiempo real. &lt;strong&gt;No hay ninguna raz&#243;n de peso para convertir todo el proceso ETL a tiempo real.&lt;/strong&gt; El ritmo de la mayor&#237;a de procesos empresariales simplemente no demandan un tratamiento en tiempo real.&lt;/p&gt;
&lt;p&gt;Hay que tener cuidado: Preguntar a los usuarios de negocio si quieren la entrega de datos en tiempo real es una invitaci&#243;n abierta para los problemas. Por supuesto, la mayor&#237;a de usuarios de negocios responder&#225;n positivamente a tener los datos actualizados m&#225;s frecuentemente, independientemente de si entienden el impacto de su petici&#243;n. Claramente este tipo de requerimiento de latencia de datos puede ser peligroso. Recomendamos dividir la dificultad del tiempo real en tres categor&#237;as: diaria, frecuente e instant&#225;nea. Necesitas que los usuarios finales describan sus requerimientos en cuanto a latencia de datos en estos t&#233;rminos y despu&#233;s dise&#241;ar tu soluci&#243;n ETL apropiadamente para respaldar cada set de requerimientos:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;&amp;quot;Inst&#225;ntaneo&amp;quot;&lt;/strong&gt; significa que los datos visibles en la pantalla del usuario final representan el estado real del sistema de fuente de transacci&#243;n en cada instante. Cuando el estado del sistema de la fuente cambia, la pantalla debe tambi&#233;n responder instant&#225;neamente.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;quot;Frecuentemente&amp;quot;&lt;/strong&gt; significa que los datos visibles por el usuario final, se actualizan muchas veces al d&#237;a pero no se garantiza que representen el  valor correcto absoluto en cada instante.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&amp;quot;Diariamente&amp;quot;&lt;/strong&gt; significa que los datos visibles en la pantalla corresponden a la informaci&#243;n del sistema fuente al final del d&#237;a anterior laborable.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;En este art&#237;culo hemos discutido unas cuentas claves que deben ser evaluadas durante la creaci&#243;n de la arquitectura ETL para mantener DWH dimensional.&lt;/p&gt;
&lt;p&gt;Pocas veces hay una sola elecci&#243;n correcta para cualquiera de estas decisiones. Como siempre, la decisi&#243;n correcta depender&#225; de las necesidades y caracter&#237;sticas de tu empresa.&lt;/p&gt;
&lt;p&gt;Art&#237;culo original: &lt;a href=&quot;http://www.kimballgroup.com/2009/10/six-key-decisions-for-etl-architectures/&quot;&gt;http://www.kimballgroup.com/2009/10/six-key-decisions-for-etl-architectures/&lt;/a&gt;&lt;/p&gt;

	   
	  
	  &lt;/div&gt;</description>
</item>
 <item>
      <guid isPermaLink="true">https://datawarehouse.es/2009/ciclo-de-vida-kimball.html</guid>
      <link>https://datawarehouse.es/2009/ciclo-de-vida-kimball.html</link>
      <title>Consejo de dise&#241;o #115. El ciclo de vida Kimball resumido.</title>
      <pubDate>Tue, 04 Aug 2009 01:30:41 GMT</pubDate>
      <atom:updated>2009-08-04T01:30:41Z</atom:updated>
      <description>
	  &lt;div style=&quot;width:700px&quot;&gt;&lt;img class=&quot;w100p&quot; src=&quot;https://datawarehouse.es/blog/images/&quot; /&gt;
	  &lt;p&gt;Recientemente, en una clase sobre el Lifecycle del Data Warehouse un estudiante me pregunt&#243; a cerca de una visi&#243;n resumida del enfoque Kimball para compartirlo con su director. Estaba contento de que me preguntara porque asum&#237;a que hab&#237;amos publicado un resumen ejecutivo sobre esto. Para mi sorpresa, nuestra &#250;nica publicaci&#243;n sobre la visi&#243;n del ciclo de vida era un cap&#237;tulo en un libro de  herramientas de ayuda. Este consejo de dise&#241;o incluye el vac&#237;o de contenido inesperado en nuestros archivos.&lt;/p&gt;
&lt;p&gt;El enfoque Kimball sobre el ciclo de vida lleva d&#233;cadas siendo utilizado. Los conceptos fueron inicialmente establecidos en 1980 por miembros de Kimball Group y diversos colegas de &lt;em&gt;Metaphor Computer Systems&lt;/em&gt;. Cuando publicamos la metodolog&#237;a por primera vez en The Data Warehouse Lifecycle Toolkit en 1998, lo  llamamos &lt;em&gt;&amp;quot;Business Dimensional Lifecycle&amp;quot;&lt;/em&gt; porque este t&#237;tulo reforzaba tres conceptos fundamentales:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Se centraba en a&#241;adir valor empresarial en la organizaci&#243;n&lt;/li&gt;
&lt;li&gt;Estructuraba  dimensionalmente los datos proporcionados a Negocio v&#237;a reportes y consultas.&lt;/li&gt;
&lt;li&gt;Desarrollaba iterativamente la soluci&#243;n en incrementos manejables antes que facilitar un Big Bang que se pudiese entregar.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Rebobinando a 1990, nuestra metodolog&#237;a fue una de las pocas que recalcaban este conjunto de principios centrales, por tanto el t&#237;tulo El “Business Dimensional Lifecycle” diferenciaba nuestro enfoque de otros existentes en la industria.&lt;/p&gt;
&lt;p&gt;En un avance r&#225;pido hacia 2008 cuando publicamos la segunda edici&#243;n de “&lt;em&gt;The Data Warehouse Lifecycle Toolkit&lt;/em&gt;”, todav&#237;a creemos absolutamente en estos conceptos, pero la industria ha evolucionado. Nuestros principios hab&#237;an llegado a ser la corriente principal en las mejores pr&#225;cticas ofrecidas por muchos, as&#237; que reducimos el nombre oficial de la metodolog&#237;a a simplemente &amp;quot;&lt;em&gt;Kimball Lifecylce&lt;/em&gt;&amp;quot;.&lt;/p&gt;
&lt;p&gt;A pesar de  los avances dram&#225;ticos en tecnolog&#237;a y entendimiento durante las dos &#250;ltimas d&#233;cadas, las construcciones b&#225;sicas del ciclo de vida de Kimball han permanecido sorprendentemente constantes.&lt;/p&gt;
&lt;p&gt;Nuestro enfoque para el dise&#241;o, desarrollando una y otra vez soluciones DW/BI, est&#225; probado y verificado. Ha sido utilizados por miles de equipos de proyectos virtualmente en todas las industrias, en el &#225;rea de aplicaci&#243;n, en las funciones de negocio y en las plataformas de negocio. Una y otra vez se ha comprobado que el enfoque del &lt;em&gt;Lifecylce Kimball&lt;/em&gt; funciona.&lt;/p&gt;
&lt;p&gt;El enfoque Kimball del Ciclo de vida se ilustra en la Figura 1. Una implementaci&#243;n exitosa del DW/BI depende de una combinaci&#243;n apropiada de numerosas tareas y componentes.  No es suficiente tener un modelo de datos perfecto o la mejor tecnolog&#237;a desarrollada. El diagrama del ciclo de vida es la hoja de ruta general que describe las tareas requeridas para un dise&#241;o efectivo, desarrollo y despliegue.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://datawarehouse.es/images/dt-115-lifecycle-kimball.png&quot; alt=&quot;Imagen 1&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Figura 1. El diagrama del Ciclo de vida Kimball.&lt;/p&gt;
&lt;h3&gt;Direcci&#243;n y planificaci&#243;n del programa/proyecto&lt;/h3&gt;
&lt;p&gt;El primer recuadro en la ruta se centra en conseguir lanzar el programa/proyecto, incluyendo la determinaci&#243;n del alcance, la justificaci&#243;n y la dotaci&#243;n de personal. A lo largo del ciclo de vida, la planificaci&#243;n y la direcci&#243;n de las tareas del proyecto mantiene las actividades en marcha.&lt;/p&gt;
&lt;h3&gt;Requisitos del negocio&lt;/h3&gt;
&lt;p&gt;Identificar las necesidades del negocio es una tarea clave en el ciclo de vida Kimball ya que estos descubrimientos dirigen la mayor&#237;a de decisiones ascendentes y descendentes. Las necesidades se recogen para determinar los factores clave que repercuten en el negocio centr&#225;ndose en lo que los usuarios de negocio hacen hoy (o lo que quieren hacer en el futuro) en lugar de preguntar “&#191;Qu&#233; quieres almacenar en el almac&#233;n de datos?”, se identifican las oportunidades m&#225;s significativas en la empresa, bas&#225;ndose en el valor del negocio y su viabilidad. Posteriormente las necesidades detalladas son recopiladas en la primera iteraci&#243;n del sistema de desarrollo DW/BI. Tres rutas paralelas del ciclo de vida siguen la definici&#243;n de las necesidades.&lt;/p&gt;
&lt;h3&gt;Ruta de tecnolog&#237;a&lt;/h3&gt;
&lt;p&gt;Los entornos DW/BI se encargan de la integraci&#243;n de numerosas tecnolog&#237;as, almacenes de datos y metadatos asociados. La ruta de la tecnolog&#237;a empieza con el dise&#241;o del sistema de arquitectura para establecer una lista de la compra de las capacidades necesarias, seguidas de la selecci&#243;n e instalaci&#243;n de productos que satisfagan esas necesidades de la arquitectura.&lt;/p&gt;
&lt;h3&gt;Ruta de datos&lt;/h3&gt;
&lt;p&gt;La ruta de datos empieza con el dise&#241;o de un modelo dimensional como objetivo para enfrentarse a los requisitos del negocio, mientras consideramos las realidades de datos subyacentes. El mundo Kimball es sin&#243;nimo del modelo dimensional donde los datos se dividen en medidas o dimensiones descriptivas. Los modelos dimensionales pueden estar instanciados en bases de datos relacionales, referidas como esquemas de estrella, o bases de datos multidimensionales, conocidas como los cubos OLAP. Independientemente de la plataforma, los modelos dimensionales intentar dirigirse a dos objetivos simult&#225;neos: facilidad de uso desde la perspectiva de los usuarios y r&#225;pidez en la realizaci&#243;n de la consulta.&lt;/p&gt;
&lt;p&gt;La matriz empresarial (EDW Bus Matrix) es un entregable clave ya que representa  el n&#250;cleo de los procesos empresariales de la organizaci&#243;n y las dimensiones conformadas comunes asociadas. Es el prototipo de datos para asegurar la integraci&#243;n de la empresa de arriba abajo con un intercambio manejable desde abajo hacia arriba centr&#225;ndose en un &#250;nico proceso de negocio a la vez. La matriz en bus  es tremendamente importante porque sirve simult&#225;neamente como una gu&#237;a t&#233;cnica, una gu&#237;a para gestionar, y un f&#243;rum para comunicarse con ejecutivos.&lt;/p&gt;
&lt;p&gt;El modelo dimensional se convierte en un dise&#241;o f&#237;sico donde las estrategias de optimizaci&#243;n del rendimiento son tomadas en cuenta. De esta manera, se aborda el dise&#241;o del sistema ETL y los desaf&#237;os para el desarrollo. El ciclo de vida describe 34 subsistemas del proceso de extracci&#243;n transformaci&#243;n y carga (ETL). Estos subsistemas  se agrupan en 4 operaciones mayores: (1) extraer los datos de la fuente, (2) llevar a cabo la limpieza y el ajuste de las transformaciones; (3) proporcionar los datos en la capa de presentaci&#243;n y (4) dirigir el proceso ETL de mantenimiento y entorno.&lt;/p&gt;
&lt;h3&gt;Ruta de la inteligencia de negocios&lt;/h3&gt;
&lt;p&gt;Mientras que algunos miembros de proyectos est&#225;n inmersos en la tecnolog&#237;a y los datos, otros se centran en identificar y construir un amplio rango de  aplicaciones BI, incluyendo informes estandarizados, consultas parametrizadas, tableros, cuadros de mando, modelos anal&#237;ticos, aplicaciones de extracci&#243;n de datos junto con las interfaces de navegaci&#243;n asociadas.&lt;/p&gt;
&lt;h3&gt;Implementaci&#243;n, mantenimiento y crecimiento:&lt;/h3&gt;
&lt;p&gt;Las tres rutas de ciclos de vida convergen en la implementaci&#243;n, reuniendo la tecnolog&#237;a, los datos y las aplicaciones BI. La implementaci&#243;n iterada entra en fase de mantenimiento, mientras que el crecimiento vuelve atr&#225;s hacia la planificaci&#243;n del proyecto para la pr&#243;xima iteraci&#243;n del sistema DW/BI. Recuerda que el sistema DW/BI es un proceso a largo plazo, &#161;no un proyecto que se hace una sola vez!.&lt;/p&gt;
&lt;p&gt;A lo largo del ciclo de vida Kimball, hay un tema recurrente reconociendo que los profesionales del DW/BI deben combinar los requerimientos de los usuarios de negocio con las realidades subyacentes de los datos fuente, tecnolog&#237;a y recursos relacionados. Los equipos de proyecto que se centran exclusivamente en las necesidades (o realidades) de un modo aislado, inevitablemente tendr&#225;n que hacer frente a riesgos en forma de retrasos en las entregas y/o adopci&#243;n por parte de los usuarios.&lt;/p&gt;
&lt;p&gt;Finalmente, como hemos dicho en otras ocasiones, y seguro que repetiremos en el  futuro: Independientemente de los objetivos espec&#237;ficos DW/BI de tu organizaci&#243;n, creemos que tu objetivo general debe ser la aceptaci&#243;n por parte de los usuarios de negocio del DW/BI para el apoyar la toma de decisiones. Este objetivo debe permanecer en el ojo del hurac&#225;n durante el dise&#241;o, desarrollo e implementaci&#243;n del ciclo de vida de cualquier sistema data warehouse o business intelligence.&lt;/p&gt;
&lt;p&gt;Art&#237;culo original: &lt;a href=&quot;http://www.kimballgroup.com/2009/08/design-tip-115-kimball-lifecycle-in-a-nutshell/&quot;&gt;http://www.kimballgroup.com/2009/08/design-tip-115-kimball-lifecycle-in-a-nutshell/&lt;/a&gt;&lt;/p&gt;

	   
	  
	  &lt;/div&gt;</description>
</item>
 <item>
      <guid isPermaLink="true">https://datawarehouse.es/2009/los-10-mandamientos-de-kimball.html</guid>
      <link>https://datawarehouse.es/2009/los-10-mandamientos-de-kimball.html</link>
      <title>Las 10 reglas esenciales del modelado dimensional</title>
      <pubDate>Fri, 29 May 2009 00:07:50 GMT</pubDate>
      <atom:updated>2009-05-29T00:07:50Z</atom:updated>
      <description>
	  &lt;div style=&quot;width:700px&quot;&gt;&lt;img class=&quot;w100p&quot; src=&quot;https://datawarehouse.es/blog/images/&quot; /&gt;
	  &lt;p&gt;Un estudiante que asisti&#243; recientemente a una de las clases de modelado dimensional de &lt;em&gt;Kimball Gruop&lt;/em&gt; me pidi&#243; una lista de &amp;quot;10 Mandamientos de Kimball&amp;quot; para el modelado dimensional. Nos abstendremos de utilizar la terminolog&#237;a religiosa, pero debemos decir que estas reglas incluyen recomendaciones que se deben seguir necesariamente junto a otras buenas pr&#225;cticas que conviene tener en cuenta.&lt;/p&gt;
&lt;h3&gt;Regla #1: Cargar los datos at&#243;micos en estructuras dimensionales&lt;/h3&gt;
&lt;p&gt;Los modelos dimensionales deben estar cargados con el m&#225;ximo detalle para poder dar respuesta a los filtros impredecibles y agrupaciones requeridas en las consultas de los usuarios de negocio. Normalmente los usuarios no necesitan ver un &#250;nico registro cada vez, pero no puedes predecir de que manera arbitraria querr&#225;n visualizar y consultar estos detalles.&lt;/p&gt;
&lt;p&gt;Si s&#243;lo est&#225;n disponibles los datos agregados, habr&#225;s hecho conjeturas sobre el patr&#243;n de utilizaci&#243;n de la base de datos que ocasionar&#225; que los usuarios se den contra una pared cuando intenten indagar en profundidad en los detalles Por supuesto, los detalles at&#243;micos se pueden completar con res&#250;menes de los modelos dimensionales que proporcionan ventajas en el rendimiento de consultas comunes, pero los usuarios de negocio no pueden trabajar s&#243;lo con res&#250;menes de datos; necesitan los detalles espec&#237;ficos para responder sus preguntas cambiantes.&lt;/p&gt;
&lt;h3&gt;Regla #2: Estructura de los modelos dimensionales en funci&#243;n de los procesos de negocio&lt;/h3&gt;
&lt;p&gt;Los procesos empresariales son las actividades llevadas a cabo por tu organizaci&#243;n; representan sucesos, como tomar un pedido o facturar a un cliente.&lt;/p&gt;
&lt;p&gt;Normalmente, los procesos empresariales recopilan o generan una &#250;nica m&#233;trica asociada con cada suceso. Estas m&#233;tricas se traducen en hechos, con cada proceso empresarial representado por un &#250;nica tabla at&#243;mica de hechos. Adem&#225;s del proceso &#250;nico de tablas de hechos, las tablas de hechos consolidadas se crean a veces para combinar m&#233;tricas de m&#250;ltiples procesos en una tabla de hechos con un mismo nivel de detalles. De nuevo, las tablas de hecho consolidadas son un complemento a los detalles, no un sustituto de ellas.&lt;/p&gt;
&lt;h3&gt;Regla #3: Asegurarse de que cada tabla de hechos tiene una tabla de dimensi&#243;n tiempo asociada&lt;/h3&gt;
&lt;p&gt;Los sucesos de medici&#243;n descritos en la &lt;em&gt;Regla #2&lt;/em&gt; siempre tienen una fecha asociada, tanto si es un balance mensual o una transferencia bancaria capturada en una cent&#233;sima de segundo. Cada tabla de hechos deber&#237;a tener al menos una clave externa asociada a la tabla de dimensi&#243;n de tiempo (con granularidad de d&#237;a) con atributos para calendario y con caracter&#237;sticas no est&#225;ndar sobre la fecha, tales como el mes fiscal o el indicador de las vacaciones corporativas. A veces, una tabla de hechos contiene varias claves for&#225;neas de fecha.&lt;/p&gt;
&lt;h3&gt;Regla #4: Asegurarse de que todos los hechos de la tabla de hechos tienen el mismo nivel de detalle&lt;/h3&gt;
&lt;p&gt;Hay tres tipos fundamentales para categorizar todas las tablas de hecho: transacciones, capturas peri&#243;dicas o capturas acumuladas. Independientemente del tipo de tabla de hechos, cada medici&#243;n dentro de una tabla de hechos debe presentar el mismo nivel de detalle. Cuando mezclamos hechos que presentan diferentes niveles de detalle (granularidad) en la misma tabla de hechos, estamos creando confusiones para el usuario de negocio y haremos que la aplicaci&#243;n BI sea vulnerable a ofrecer resultados err&#243;neos.&lt;/p&gt;
&lt;h3&gt;Regla #5: Resolver correspondencias muchos a muchos en tablas de hechos&lt;/h3&gt;
&lt;p&gt;Partiendo de que una tabla de hechos recopila los resultados de un proceso empresarial, naturalmente hay una relaci&#243;n muchos a muchos (M:M) entre sus claves for&#225;neas (m&#250;ltiples productos vendidos en m&#250;ltiples tiendas en m&#250;ltiples d&#237;as). Estas claves for&#225;neas nunca ser&#225;n nulas. A veces las dimensiones pueden tomar m&#250;ltiples valores para una sola medici&#243;n, como los m&#250;ltiples diagn&#243;sticos asociados en una consulta de salud o m&#250;ltiples clientes con una cuenta bancaria. En estos casos, no es razonable resolver estas dimensiones multivalor en la misma tabla de hechos, ya que esto alterar&#237;a la granularidad del suceso de medici&#243;n. Por lo tanto, deberemos utilizar una tabla puente many-to-many entre la tabla de hechos y la dimensi&#243;n.&lt;/p&gt;
&lt;h3&gt;Rule #6: Resolver correspondencias muchos a muchos en tablas de dimensiones&lt;/h3&gt;
&lt;p&gt;Las jerarqu&#237;as, o relaciones muchos a uno (M:1),  entre atributos son normalmente desnormalizadas en una tabla de dimensi&#243;n plana. Si te has pasado la mayor parte de tu carrera dise&#241;ando modelos entidad-relaci&#243;n para sistemas de procesamiento de transacciones, tendr&#225;s que resistirte a tu propia tendencia a normalizar o fragmentar la relaci&#243;n M:1 en subdimensiones m&#225;s peque&#241;as. La desnormalizaci&#243;n de dimensiones es la regla del modelado dimensional.&lt;/p&gt;
&lt;p&gt;Es relativamente com&#250;n tener m&#250;ltiples relaciones M:1  representadas en una tabla dimensional. Las relaciones uno-a-uno, como descripci&#243;n &#250;nica de un producto asociado con un c&#243;digo de producto, tambi&#233;n est&#225;n contenidos en una tabla dimensional. Ocasionalmente, las relaciones muchos-a-uno se resuelven en la tabla de hechos, como en el caso de que la tabla dimensional detallada tenga millones de filas y sus atributos est&#233;n cambiando frecuentemente. Sin embargo, utilizar la tabla de hechos para resolver relaciones M:1 debe hacerse con moderaci&#243;n.&lt;/p&gt;
&lt;h3&gt;Regla #7: Almacenar las descripciones en las tablas de dimensi&#243;n&lt;/h3&gt;
&lt;p&gt;Los c&#243;digos y, m&#225;s importante, las decodificaciones asociadas y las descripciones usadas para filtrar las consultas deben incluirse en las tablas dimensionales. Evitaremos almacenar campos de c&#243;digos cr&#237;pticos o campos descriptivos voluminosos en la misma tabla de hechos. Dicho de otro modo: No s&#243;lo guardaremos el c&#243;digo en la tabla de dimensi&#243;n asumiendo que los usuarios no necesitan decodificaciones descriptivas o que estas decodificaciones ser&#225;n llevadas a cabo por la aplicaci&#243;n de inteligencia de negocios (BI). Si es un t&#237;tulo de fila o columna o si aparece en un men&#250; desplegable, entonces debe ser considerado como un atributo dimensional.&lt;/p&gt;
&lt;p&gt;Aunque en la &lt;em&gt;Regla #5&lt;/em&gt; establecimos que la tabla de hechos de las claves for&#225;neas no deb&#237;a ser nunca nula, es tambi&#233;n recomendable evitar tener nulidades en los campos de atributo de las tablas dimensionales. Para ello, sustituiremos el valor nulo por “NA” (no aplicable) u otro valor por defecto, determinado por el administrador de datos, para reducir las confusiones en la medida de lo posible.&lt;/p&gt;
&lt;h3&gt;Regla #8: Asegurarse de que las tablas dimensionales usan claves subrogadas&lt;/h3&gt;
&lt;p&gt;Asignar claves subrogadas secuencialmente, claves sin sentido de negocio, proporciona ciertas ventajas operacionales  (excepto para la dimensi&#243;n fecha donde se asignan cronol&#243;gicamente). Algunas de estas ventajas son: claves m&#225;s peque&#241;as, lo que implica en tablas de hecho menores, menores &#237;ndices y mejor rendimiento general.&lt;/p&gt;
&lt;p&gt;Las claves subrogadas son totalmente necesarias si est&#225;s haciendo un seguimiento de los cambios en un atributo dimensional (con un nuevo registro para cada cambio en la descripci&#243;n...). Incluso si los usuarios de tu empresa no visualizan inicialmente el valor de poder seguir los cambios en los atributos, utilizar claves subrogadas har&#225; que una pol&#237;tica de cambios posterior sea menos costosa.&lt;/p&gt;
&lt;p&gt;Las claves subrogadas tambi&#233;n nos permiten relacionar m&#250;ltiples claves operacionales distintas en un perfil com&#250;n. Adem&#225;s nos protege de actividades operacionales inesperadas, como el reciclado de un n&#250;mero obsoleto de producto o la adquisici&#243;n de otra empresa con sus propios esquemas de c&#243;digo.&lt;/p&gt;
&lt;h3&gt;Regla #9: Crear dimensiones conformadas para integrar los datos de toda la empresa&lt;/h3&gt;
&lt;p&gt;Las dimensiones conformadas (tambi&#233;n conocidas como comunes, maestros, est&#225;ndar o dimensiones de referencia) son esenciales para el data warehouse en la empresa. Se gestiona una vez en el sistema ETL y se reutiliza posteriormente en m&#250;ltiples tablas de hechos. Las dimensiones conformadas proporcionan atributos descriptivos consistentes sobre modelos dimensionales y facilitan la habilidad para navegar y integrar datos desde m&#250;ltiples procesos empresariales. La matriz empresarial (Enterprise Bus Matrix) es el modelo clave para representar los procesos centrales del negocio y su  dimensionalidad asociada.&lt;/p&gt;
&lt;p&gt;Reutilizar las dimensiones conformadas reduce el tiempo de comercializaci&#243;n eliminando el dise&#241;o redundante y los esfuerzos de desarrollo. Sin embargo, las dimensiones conformadas requieren esfuerzo y inversi&#243;n en la administraci&#243;n y direcci&#243;n de datos, incluso si no necesitas que todo el mundo est&#233; de acuerdo en cuanto a todos los atributos de dimensiones para impulsar la conformidad.&lt;/p&gt;
&lt;h3&gt;Regla #10: Valora constantemente los requerimientos y las realidades para proporcionar una soluci&#243;n DW/BI que sea aceptada por los usuarios de negocios y que apoye su proceso de decisiones&lt;/h3&gt;
&lt;p&gt;Los modeladores dimensionales constantemente deben combinar las demandas de los usuarios de negocio con las realidades subyacentes de las fuentes de datos asociadas para proporcionar un dise&#241;o que pueda ser implementado y, m&#225;s importante, exista una posibilidad razonable de ser aceptado por el negocio.&lt;/p&gt;
&lt;p&gt;La confrontaci&#243;n &lt;em&gt;requerimientos-vs-realidad&lt;/em&gt; es parte del d&#237;a a d&#237;a de los profesionales DW/BI, tanto si se centran en el modelo dimensional, en la estrategia de proyecto, en la parte t&#233;cnica ETL/BI, o en la planificaci&#243;n de la arquitectura de implementaci&#243;n o mantenimiento.&lt;/p&gt;
&lt;p&gt;Si has le&#237;do regularmente nuestro Kit de art&#237;culos, o los consejos de dise&#241;o, estas reglas no deber&#237;an ser nuevas para ti. En todo caso, aqu&#237; las hemos refundido en un simple art&#237;culo de reglas que puedes consultar cuando tengas que dise&#241;ar o revisar tus modelos.&lt;/p&gt;
&lt;p&gt;&#161;Buena suerte!&lt;/p&gt;
&lt;p&gt;Art&#237;culo original: &lt;a href=&quot;http://www.kimballgroup.com/2009/05/the-10-essential-rules-of-dimensional-modeling/&quot;&gt;http://www.kimballgroup.com/2009/05/the-10-essential-rules-of-dimensional-modeling/&lt;/a&gt;&lt;/p&gt;

	   
	  
	  &lt;/div&gt;</description>
</item>
 <item>
      <guid isPermaLink="true">https://datawarehouse.es/2002/dos-ideas-potentes.html</guid>
      <link>https://datawarehouse.es/2002/dos-ideas-potentes.html</link>
      <title>Dos ideas potentes</title>
      <pubDate>Tue, 17 Sep 2002 00:00:00 GMT</pubDate>
      <atom:updated>2002-09-17T00:00:00Z</atom:updated>
      <description>
	  &lt;div style=&quot;width:700px&quot;&gt;&lt;img class=&quot;w100p&quot; src=&quot;https://datawarehouse.es/blog/images/&quot; /&gt;
	  &lt;p&gt;Hay dos ideas potentes en la creaci&#243;n de los data warehouses de m&#225;s &#233;xito. Primero, separar tus sistemas. Segundo, construir estrellas y cubos.&lt;/p&gt;
&lt;p&gt;En mi columna previa, describ&#237; un completo espectro de restricciones de dise&#241;o y realidades inevitables a las que deb&#237;a enfrentarse un dise&#241;ador de data warehouse. Era una lista de grandes proporciones de la que me preocupaba que os hiciera coger la puerta y os fuerais. Pero, tal vez, lo que hizo seguir leyendo fue mi promesa de salir de la ci&#233;naga. Aqu&#237; es donde entran las dos potentes ideas.&lt;/p&gt;
&lt;p&gt;La &#250;ltima vez, indiqu&#233; que las restricciones no negociables del dise&#241;o de un data warehouse eran el entendimiento por parte del usuario final y la velocidad en la ejecuci&#243;n de la consulta. Un almac&#233;n de datos complejo y lento es un fracaso sin importar como de elegante pueda ser el resto del dise&#241;o porque la gente para el que fue destinado no querr&#225; utilizarlo.&lt;/p&gt;
&lt;p&gt;El resto de restricciones implicaban el reconocimiento de que el dise&#241;o del DWH es extremadamente complejo. La fuente de datos, las tecnolog&#237;as de la base de datos y los entornos empresariales con los que tratamos son incre&#237;blemente complicados. As&#237; que, como buenos ingenieros, para buscar nuestro camino hacia fuera de la ci&#233;naga, debemos descomponer el problema en partes separadas manejables y poner &#233;nfasis en las t&#233;cnicas que son predecibles, reutilizables y robustas.&lt;/p&gt;
&lt;h2&gt;Separa tus sistemas&lt;/h2&gt;
&lt;p&gt;El primer paso crucial en el dise&#241;o de un almac&#233;n de datos en una empresa es separar los sistemas l&#243;gica, f&#237;sica y administrativamente.&lt;/p&gt;
&lt;p&gt;Encuentro muy &#250;til pensar en el proyecto como cuatro sistemas distintos y diferentes, de los cu&#225;les el administrador del DWH ser&#225; el responsable de solo dos. No agobiar&#233; con el t&#237;pico bloque de diagramas porque estas cuestiones son m&#225;s simples que eso.&lt;/p&gt;
&lt;p&gt;Los cuatro sistemas son:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sistema transaccional de producci&#243;n (ERP origen).&lt;/li&gt;
&lt;li&gt;Sistema data warehouse de almacenamiento (staging area system)&lt;/li&gt;
&lt;li&gt;Sistemas de presentaci&#243;n del DWH, incluyendo las herramientas de &lt;em&gt;query, reporting y analysis&lt;/em&gt;, ya sean soluciones cliente/servidor o web.&lt;/li&gt;
&lt;li&gt;Opcionalmente, herramientas anal&#237;ticas  de alta gama para la miner&#237;a de datos, forecasting, valoraci&#243;n o asignaci&#243;n.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Como administrador del DWH no debes ser responsable de los sistemas origen que captan y procesan transacciones. Ese es el trabajo de otro. No tienes que verte involucrado en soportar las funciones de auditor&#237;a legal y financiera o las funciones de retroceso y recuperaci&#243;n de estos sistemas. Son los sistemas de cajas registradoras de la compa&#241;&#237;a, y sus prioridades son diferentes que las del data warehouse.&lt;/p&gt;
&lt;p&gt;El &lt;u&gt;primer sistema&lt;/u&gt; del cu&#225;l es responsable el dise&#241;ador del DWH es el &#225;rea de almacenamiento de datos intermedio, donde los datos de producci&#243;n de los distintos or&#237;genes  es tra&#237;do, limpiado, conformado, combinado y en &#250;ltima instancia entregado  a los sistemas de presentaci&#243;n del almac&#233;n de datos.&lt;/p&gt;
&lt;p&gt;Mucho se ha escrito sobre el crucial proceso de extracci&#243;n-transformacci&#243;n-carga (ETL) en el DWH, pero  alej&#225;ndonos de este detalle, el principal requerimiento del &#225;rea de almacenamiento es que est&#225; fuera de los l&#237;mites para todos los clientes finales del almac&#233;n de datos. El &#225;rea de almacenamiento es exactamente como la cocina en un restaurante. La cocina es un lugar concurrido, incluso peligroso, lleno de cuchillos afilados y l&#237;quidos calientes. Los cocineros est&#225;n ocupados, centrados en la tarea de preparar la comida. No es apropiado permitir a los comensales entrar en una cocina profesional o permitir que los cocineros se distraigan con las cuestiones separadas de la experiencia culinaria. En t&#233;rminos de almac&#233;n de base de datos, prohibiendo el acceso de todos clientes del almac&#233;n de datos desde el &#225;rea de almacenamiento, conseguimos:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Garantizar &#243;ptimos niveles de servicio para consultar o informar.&lt;/li&gt;
&lt;li&gt;Cumplir con el nivel de seguridad del cliente.&lt;/li&gt;
&lt;li&gt;Posibilidad de construir &#237;ndices y agregaciones para el rendimiento de las consultas.&lt;/li&gt;
&lt;li&gt;Manejar conflictos l&#243;gicos y f&#237;sicos entre los pasos de consulta y limpieza de datos.&lt;/li&gt;
&lt;li&gt;Garantizar la consistencia entre las distintas fuentes de datos&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Las dos estructuras de datos dominantes para el almacenamiento de datos que son extra&#237;dos directamente del sistema de producci&#243;n son el archivo de texto plano y el esquema entidad/relaci&#243;n. Casi todo el procesamiento en el &#225;rea de almacenamiento (DWH) es clasificaci&#243;n o procesamiento secuencial simple.&lt;/p&gt;
&lt;p&gt;El &lt;u&gt;segundo sistema&lt;/u&gt; m&#225;s grande bajo el control espec&#237;fico del responsable DWH es el sistema de presentaci&#243;n. Por supuesto, este sistema es an&#225;logo al &#225;rea del comedor de un buen restaurante. El &#225;rea de comedor est&#225; dise&#241;ado para ofrecer confort a los comensales. La comida se sirve r&#225;pido y de la forma m&#225;s atractiva, y los problemas y distracciones se evitan tanto como es posible. De la misma manera, el sistema de presentaci&#243;n del almac&#233;n de datos est&#225; construido con el prop&#243;sito de mejorar la experiencia de consultar e informar. El sistema de presentaci&#243;n necesita ser simple y r&#225;pido y ofrecer los datos correctos que correspondan a las necesidades de an&#225;lisis de los usuarios finales. Tambi&#233;n, en el sistema de presentaci&#243;n, podemos manejar con facilidad la lista enumerada con anterioridad sobre los requerimientos que hab&#237;amos excluido del &#225;rea de almacenamiento.&lt;/p&gt;
&lt;p&gt;Las estructuras de datos dominantes en el &#225;rea de presentaci&#243;n son el esquema relacional de estrella y el cubo de datos de procesamiento anal&#237;tico online (OLAP). El procesamiento en el &#225;rea de presentaci&#243;n debe responder a una tormenta de grandes y peque&#241;as consultas procedentes de cualquier &#225;ngulo de los datos. A lo largo del tiempo, no habr&#225; un patr&#243;n predecible a estas consultas. Algunos dise&#241;adores le llaman &lt;em&gt;consultas ad hoc&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;El &lt;u&gt;siguiente sistema&lt;/u&gt; en nuestra lista es una capa opcional de herramientas anal&#237;ticas espec&#237;ficas de alta gama que normalmente consume datos del almac&#233;n de datos en grandes lotes. Frecuentemente estas herramientas de extracci&#243;n, predicci&#243;n, valoraci&#243;n y distribuci&#243;n de datos utilizan algoritmos especializados fuera de la experiencia normal de un dise&#241;ador de almac&#233;n de datos.&lt;/p&gt;
&lt;p&gt;Y, honestamente, muchos de estos procesos tienen un componente interpretativo o pol&#237;tico que es sabiamente separado  del almac&#233;n de datos. Por ejemplo, la miner&#237;a de datos como disciplina es una tarea interpretativa compleja que involucra una completa colecci&#243;n de potentes t&#233;cnicas anal&#237;ticas, muchas de las cuales no son entendidas o cre&#237;das del todo por la comunidad de usuarios. La miner&#237;a de datos requiere un profesional experto en data mining cualificado para utilizar las herramientas de manera efectiva y presentar los resultados de la mineria de datos a la comunidad.&lt;/p&gt;
&lt;p&gt;Adem&#225;s, como he mencionado frecuentemente, hay un desajuste fundamental entre el data mining y el almac&#233;n de datos. La miner&#237;a de datos frecuentemente necesita  examinar miles o millones de observaciones una y otra vez, a velocidades extremas. No es f&#225;cil de sostener directamente desde el data warehouse. Es mejor manejar el set de observaci&#243;n desde un equipo de extracci&#243;n de datos, s&#243;lo una vez.&lt;/p&gt;
&lt;p&gt;Otro ejemplo de herramienta anal&#237;tica de alta gama que el almac&#233;n de datos debe evitar es el sistema de distribuci&#243;n para asignar costes a las distintas l&#237;neas de negocios en tu organizaci&#243;n para calcular la rentabilidad global. No s&#243;lo puede ser un paso complejo de procesar fuera de las posibilidades de la mayor&#237;a de las herramientas de consulta e informe, tambi&#233;n es un asunto delicado pol&#237;ticamente. Dejemos que el departamento financiero haga las asignaciones, y tu (el almac&#233;n de datos) estar&#225;s encantado de almacenar los resultados.&lt;/p&gt;
&lt;h2&gt;Estrellas y cubos sim&#233;tricos&lt;/h2&gt;
&lt;p&gt;La mayor parte de las &#225;reas de representaci&#243;n hoy en d&#237;a est&#225;n dominadas por esquemas relacionales de esquemas de estrella y cubos de datos multidimensionales OLAP. Estas estructuras de datos han demostrado durante los  &#250;ltimos 30 a&#241;os ser las que mejor entienden los usuarios finales. Recordad que el entendimiento es una de las dos condiciones no negociables en el dise&#241;o.&lt;/p&gt;
&lt;p&gt;La simplicidad de los esquemas de estrella y cubos OLAP ha permitido a los brillantes dise&#241;adores de software centrarse en los algoritmos m&#225;s potentes para ofrecer un rendimiento r&#225;pido en las consultas. Recordad que la velocidad es la otra condici&#243;n no negociable en el dise&#241;o.&lt;/p&gt;
&lt;p&gt;La simetr&#237;a de ambas, el esquema de estrella y el cubo OLAP tambi&#233;n permiten:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Interfaz de usuario predecible que puede “aprender” qu&#233; hacer en el momento de la consulta.&lt;/li&gt;
&lt;li&gt;Escenarios administrativos predecibles en el DWH porque toda la estructura de datos tienen aspecto parecido.&lt;/li&gt;
&lt;li&gt;Respuestas de implementaci&#243;n predecibles cuando nuevos tipos de datos est&#225;n disponibles.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Por supuesto, el esquema de estrella y el cubo OLAP est&#225;n estrechamente relacionados. Los esquemas de estrellas son los m&#225;s apropiados para los conjuntos grandes de datos, con muchos millones o billones de mediciones num&#233;ricas o muchos millones de miembros en una dimensi&#243;n de cliente o de producto.&lt;/p&gt;
&lt;p&gt;Los cubos OLAP son los m&#225;s apropiados para conjuntos de datos m&#225;s peque&#241;os donde las herramientas anal&#237;ticas pueden realizar comparaciones de datos complejas y c&#225;lculos. En casi todos los entornos de cubos OLAP, se recomienda que introduzcas originalmente los datos en un esquema de estructura de estrella, y despu&#233;s utilices asistentes para transformar los datos en el cubo de OLAP. De esa manera, toda las potentes herramientas ETL del &#225;rea de almacenamiento que tratan con los archivos planos y esquemas entidades/relaciones participan en la carga de los datos OLAP.  Y, por supuesto, el sistema de esquema h&#237;brido estrella-OLAP permite que se pueda realizar &lt;em&gt;drill-down&lt;/em&gt; entre los los grandes conjuntos de datos en estrella y los cubos de datos OLAP , todos bajo una &#250;nica interfaz de usuario.&lt;/p&gt;
&lt;h2&gt;La gran recompensa&lt;/h2&gt;
&lt;p&gt;La gran recompensa final de construir el sistema de representaci&#243;n en el almac&#233;n de datos sobre esquemas sim&#233;tricos de estrella y cubos OLAP es un resultado predecible con puntos comunes para encajar datos desde toda la empresa.&lt;/p&gt;
&lt;p&gt;En mi pr&#243;xima columna, pondr&#233; al descubierto las t&#233;cnicas para conformar las dimensiones y hechos de las distintas y dispares fuentes de datos de tu gran empresa.  Estas dimensiones conformadas (y hechos) ser&#225;n la base de un &lt;em&gt;almac&#233;n de datos de aquitectura de bus&lt;/em&gt;--- un conjunto de puntos conectados que proporcionan poder a todas las l&#237;neas de transmisi&#243;n, y justo como el bus en tu ordenador proporciona datos a todos los perif&#233;ricos.&lt;/p&gt;
&lt;h2&gt;&#191;Qu&#233; hemos conseguido?&lt;/h2&gt;
&lt;p&gt;Hasta ahora hemos implementado dos ideas potentes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Primero, hemos separado l&#243;gicamente, f&#237;sicamente y administrativamente los sistemas de nuestro entorno en 4 distritos distintos. Realmente necesitas 4 sistemas inform&#225;ticos diferentes, pero &lt;strong&gt;&#161;eres responsable solo de dos de ellos!&lt;/strong&gt; Nuestros dos sistemas de almacenes de datos tambi&#233;n nos permiten separar las responsabilidades del almacenamiento de datos y las responsabilidades de consultas de los usuarios finales.&lt;/li&gt;
&lt;li&gt;Segundo, hemos llenado nuestra &#225;rea de presentaci&#243;n del almac&#233;n de datos con esquemas de estrellas y cubos de datos OLAP, las &#250;nicas estructuras entendibles, y que pueden soportar el ataque ad hoc.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Aunque claramente no hemos solucionado todas las  complejas restricciones de dise&#241;o y realidades inevitables, hemos neutralizado en gran parte el desaf&#237;o global, solamente impulsando estas dos potentes ideas. Vuelve a mi columna previa y revisa la lista. Hemos conseguidos (1) grandes partes comprensibilidad, (2) rapidez en las consultas, (3) los tres costes mencionados en esa columna, (4) los riesgos de la centralizaci&#243;n inapropiada, (5) la necesidad de desarrollo incremental, (6) manejar continuos cambios consistentes en peque&#241;as y grandes sorpresas y (7) como pensar en el papel de los data marts. Quiz&#225; hay esperanza.&lt;/p&gt;
&lt;p&gt;Art&#237;culo original: &lt;a href=&quot;http://www.kimballgroup.com/2002/09/two-powerful-ideas/&quot;&gt;http://www.kimballgroup.com/2002/09/two-powerful-ideas/&lt;/a&gt;&lt;/p&gt;

	   
	  
	  &lt;/div&gt;</description>
</item>


   
</channel>
</rss>
